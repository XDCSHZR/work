{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 收银台免密补贴EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 增益模型 —— 分档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/odin/jarretthan/anaconda3/envs/deepctr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_194913/135023387.py\", line 10, in <module>\n",
      "    import seaborn as sns\n",
      "  File \"/home/odin/jarretthan/anaconda3/envs/deepctr/lib/python3.7/site-packages/seaborn/__init__.py\", line 12, in <module>\n",
      "    from .widgets import *  # noqa: F401,F403\n",
      "  File \"/home/odin/jarretthan/anaconda3/envs/deepctr/lib/python3.7/site-packages/seaborn/widgets.py\", line 7, in <module>\n",
      "    from ipywidgets import interact, FloatSlider, IntSlider\n",
      "  File \"/home/odin/jarretthan/anaconda3/envs/deepctr/lib/python3.7/site-packages/ipywidgets/__init__.py\", line 25, in <module>\n",
      "    from .widgets import *\n",
      "  File \"/home/odin/jarretthan/anaconda3/envs/deepctr/lib/python3.7/site-packages/ipywidgets/widgets/__init__.py\", line 11, in <module>\n",
      "    from .widget_bool import Checkbox, ToggleButton, Valid\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 724, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 818, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 916, in get_data\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/odin/jarretthan/anaconda3/envs/deepctr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/odin/jarretthan/anaconda3/envs/deepctr/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/odin/jarretthan/anaconda3/envs/deepctr/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/odin/jarretthan/anaconda3/envs/deepctr/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/odin/jarretthan/anaconda3/envs/deepctr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/odin/jarretthan/anaconda3/envs/deepctr/lib/python3.7/inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/home/odin/jarretthan/anaconda3/envs/deepctr/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/home/odin/jarretthan/anaconda3/envs/deepctr/lib/python3.7/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/home/odin/jarretthan/anaconda3/envs/deepctr/lib/python3.7/linecache.py\", line 137, in updatecache\n",
      "    lines = fp.readlines()\n",
      "  File \"/home/odin/jarretthan/anaconda3/envs/deepctr/lib/python3.7/codecs.py\", line 319, in decode\n",
      "    def decode(self, input, final=False):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_194913/135023387.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/site-packages/seaborn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maxisgrid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxkcd_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrayons\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/site-packages/seaborn/widgets.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mipywidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minteract\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloatSlider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntSlider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/site-packages/ipywidgets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtraitlets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdlink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/site-packages/ipywidgets/widgets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_core\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCoreWidget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_bool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCheckbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mToggleButton\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwidget_button\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mButton\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mButtonStyle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2102\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepctr/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import re\n",
    "import copy\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import causalml\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import utils\n",
    "import propensity\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from supervised.automl import AutoML\n",
    "from causalml.inference.meta import BaseSClassifier, BaseTClassifier, BaseXClassifier, BaseRClassifier\n",
    "\n",
    "from causalml_visualize.visualize_ import plot_all\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_row', 500)\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas(desc='pandas bar')\n",
    "logger = logging.getLogger('causalml')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = str(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/no_secret_bt/sample_label_feature_fusion_20220206_20220227.txt', sep='\\t', encoding='utf-8')\n",
    "df = pd.read_csv('data/no_secret_bt/sample_label_feature_aspiration_20220206_20220227.txt', sep='\\t', encoding='utf-8')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=['obs_dt'])['uid'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=['coupon'])['uid'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "80373 / 1080373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['obs_dt'] = pd.to_datetime(df['obs_dt'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(df, 'data/no_secret_bt/df_sample_label_feature_fusion_20220206_20220227.pickle')\n",
    "utils.save_pickle(df, 'data/no_secret_bt/df_sample_label_feature_aspiration_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = utils.load_pickle('data/no_secret_bt/df_sample_label_feature_fusion_20220206_20220227.pickle')\n",
    "df_all = utils.load_pickle('data/no_secret_bt/df_sample_label_feature_aspiration_20220206_20220227.pickle')\n",
    "\n",
    "print(df_all.shape)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_des = utils.df_des(df_all)\n",
    "print(df_all_des.shape)\n",
    "df_all_des.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_des.to_csv('data/no_secret_bt/df_des_sample_label_feature_fusion_20220206_20220227.csv', encoding='utf-8')\n",
    "df_all_des.to_csv('data/no_secret_bt/df_des_sample_label_feature_aspiration_20220206_20220227.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_id_y = ['uid', 'obs_dt', 'coupon', 'label']\n",
    "list_feats_x = [x for x in df_all.columns if x not in list_feats_id_y]\n",
    "print(len(list_feats_x))\n",
    "list_feats_x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(list_feats_x, 'data/no_secret_bt/list_feats/list_feats_x_feature_fusion_20220206_20220227.pickle')\n",
    "utils.save_pickle(list_feats_x, 'data/no_secret_bt/list_feats/list_feats_x_feature_aspiration_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_std_0 = [x for x in df_all_des[df_all_des['std']==0].index]\n",
    "print(len(list_feats_x_std_0))\n",
    "list_feats_x_std_0[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(list_feats_x_std_0, 'data/no_secret_bt/list_feats/list_feats_x_std_0_feature_fusion_20220206_20220227.pickle')\n",
    "utils.save_pickle(list_feats_x_std_0, 'data/no_secret_bt/list_feats/list_feats_x_std_0_feature_aspiration_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_std = [x for x in list_feats_x if x not in list_feats_x_std_0]\n",
    "print(len(list_feats_x_std))\n",
    "list_feats_x_std[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(list_feats_x_std, 'data/no_secret_bt/list_feats/list_feats_x_std_feature_fusion_20220206_20220227.pickle')\n",
    "utils.save_pickle(list_feats_x_std, 'data/no_secret_bt/list_feats/list_feats_x_std_feature_aspiration_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* F检验（treatment+X，分组加权平均）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_feats_x_std = utils.load_pickle('data/no_secret_bt/list_feats/list_feats_x_std_feature_fusion_20220206_20220227.pickle')\n",
    "list_feats_x_std = utils.load_pickle('data/no_secret_bt/list_feats/list_feats_x_std_feature_aspiration_20220206_20220227.pickle')\n",
    "\n",
    "print(len(list_feats_x_std))\n",
    "list_feats_x_std[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy causalml中的代码\n",
    "# 修改应用于multi-treatment（多档金额），分组计算，取均值\n",
    "def uplift_filter_F_one_feature(data, treatment_group, treatment_indicator, feature_name, y_name):     \n",
    "    Y = data[y_name]\n",
    "    X = data[[treatment_indicator, feature_name]]\n",
    "    X = sm.add_constant(X)\n",
    "    X['{}-{}'.format(treatment_indicator, feature_name)] = X[[treatment_indicator, feature_name]].product(axis=1)\n",
    "    \n",
    "    model = sm.OLS(Y, X)\n",
    "    result = model.fit()\n",
    "    \n",
    "    F_test = result.f_test(np.array([0, 0, 0, 1]))\n",
    "    F_test_result = pd.DataFrame({\n",
    "        'feature': feature_name, \n",
    "        'p_value_{tg}'.format(tg=treatment_group): F_test.pvalue\n",
    "    }, index=[0]).reset_index(drop=True)\n",
    "    \n",
    "    return F_test_result\n",
    "\n",
    "\n",
    "def uplift_filter_F(data, treatment_name, control_group, treatments_group, features_name, y_name, \n",
    "                    treatments_group_num=None):\n",
    "    '''\n",
    "    data: pandas.DataFrame\n",
    "    treatment_name: string\n",
    "    control_group: string\\int\\double\n",
    "    treatment_group: list[string\\int\\double]\n",
    "    features_name: list[string]\n",
    "    y_name: string\n",
    "    '''\n",
    "    \n",
    "    f_test = pd.DataFrame({'feature': features_name})\n",
    "    \n",
    "    for treatment_group in treatments_group:\n",
    "        data_tmp = data[data[treatment_name].isin([control_group, treatment_group])]\n",
    "        data_tmp['treatment_indicator'] = 0\n",
    "        data_tmp.loc[data_tmp[treatment_name]==treatment_group, 'treatment_indicator'] = 1\n",
    "        \n",
    "        list_f_test_tg = []\n",
    "        try:\n",
    "            with tqdm(features_name) as t:\n",
    "                for feature_name in t:\n",
    "                    f_test_tmp = uplift_filter_F_one_feature(data_tmp, treatment_group, 'treatment_indicator', feature_name, y_name)\n",
    "                    list_f_test_tg.append(f_test_tmp)\n",
    "        except KeyboardInterrupt:\n",
    "            t.close()\n",
    "            raise\n",
    "        t.close()\n",
    "        \n",
    "        f_test_tg = pd.concat(list_f_test_tg, axis=0)\n",
    "        f_test_tg.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        f_test = f_test.merge(f_test_tg, on='feature', how='left')\n",
    "    \n",
    "    if treatments_group_num is None:\n",
    "        f_test['p_value_mean'] = f_test[[x for x in f_test.columns if x != 'feature']].mean(axis=1)\n",
    "    else:\n",
    "        f_test['p_value_mean'] = f_test[[x for x in f_test.columns if x != 'feature']].\\\n",
    "            agg(func=np.average, axis=1, weights=treatments_group_num)\n",
    "    f_test.sort_values(by=['p_value_mean'], ascending=[True], inplace=True)\n",
    "    \n",
    "    return f_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_group = 0.0\n",
    "treatments_group = [0.2, 0.5, 1.0, 1.5, 1.8]\n",
    "weights = [48304, 281640, 51025, 39244, 30853]\n",
    "f_test = uplift_filter_F(df_all, 'coupon', control_group, treatments_group, list_feats_x_std, 'label', treatments_group_num=weights)\n",
    "f_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_test.to_csv('data/no_secret_bt/f_test/feature_fusion_20220206_20220227.csv', encoding='utf-8', index=False)\n",
    "f_test.to_csv('data/no_secret_bt/f_test/feature_aspiration_20220206_20220227.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_feats_x_ft_no_select = f_test[(f_test['p_value_mean']>0.05)|(f_test['p_value_mean'].isna())]['feature'].values.tolist()\n",
    "print(len(list_feats_x_ft_no_select))\n",
    "list_feats_x_ft_no_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(list_feats_x_ft_no_select, 'data/no_secret_bt/list_feats/list_feats_x_ht_no_select_feature_fusion_20220206_20220227.pickle')\n",
    "utils.save_pickle(list_feats_x_ft_no_select, 'data/no_secret_bt/list_feats/list_feats_x_ht_no_select_feature_aspiration_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_ht = [x for x in list_feats_x_std if x not in list_feats_x_ft_no_select]\n",
    "print(len(list_feats_x_ht))\n",
    "list_feats_x_ht[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(list_feats_x_ht, 'data/no_secret_bt/list_feats/list_feats_x_ht_feature_fusion_20220206_20220227.pickle')\n",
    "utils.save_pickle(list_feats_x_ht, 'data/no_secret_bt/list_feats/list_feats_x_ht_feature_aspiration_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 模型\n",
    "* 特征重要性\n",
    "* PI方法，使用lgb+X-learner进行建模预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_feats_x_ht = utils.load_pickle('data/no_secret_bt/list_feats/list_feats_x_ht_feature_fusion_20220206_20220227.pickle')\n",
    "list_feats_x_ht = utils.load_pickle('data/no_secret_bt/list_feats/list_feats_x_ht_feature_aspiration_20220206_20220227.pickle')\n",
    "\n",
    "print(len(list_feats_x_ht))\n",
    "list_feats_x_ht[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id，treatment，X，y\n",
    "df_sample_unique_id = df_all[['uid', 'obs_dt']]\n",
    "df_sample_unique_treatment = df_all['coupon']\n",
    "df_sample_unique_y = df_all['label']\n",
    "df_sample_unique_X = df_all[list_feats_x_ht]\n",
    "\n",
    "print(df_sample_unique_id.shape)\n",
    "print(df_sample_unique_treatment.shape)\n",
    "print(df_sample_unique_y.shape)\n",
    "print(df_sample_unique_X.shape)\n",
    "\n",
    "# utils.save_pickle(df_sample_unique_id, 'data/no_secret_bt/df_sample_unique_id_feature_fusion_20220206_20220227.pickle')\n",
    "# utils.save_pickle(df_sample_unique_treatment, 'data/no_secret_bt/df_sample_unique_treatment_feature_fusion_20220206_20220227.pickle')\n",
    "# utils.save_pickle(df_sample_unique_y, 'data/no_secret_bt/df_sample_unique_y_feature_fusion_20220206_20220227.pickle')\n",
    "# utils.save_pickle(df_sample_unique_X, 'data/no_secret_bt/df_sample_unique_X_feature_fusion_20220206_20220227.pickle')\n",
    "utils.save_pickle(df_sample_unique_id, 'data/no_secret_bt/df_sample_unique_id_feature_aspiration_20220206_20220227.pickle')\n",
    "utils.save_pickle(df_sample_unique_treatment, 'data/no_secret_bt/df_sample_unique_treatment_feature_aspiration_20220206_20220227.pickle')\n",
    "utils.save_pickle(df_sample_unique_y, 'data/no_secret_bt/df_sample_unique_y_feature_aspiration_20220206_20220227.pickle')\n",
    "utils.save_pickle(df_sample_unique_X, 'data/no_secret_bt/df_sample_unique_X_feature_aspiration_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample_unique_id = utils.load_pickle('data/no_secret_bt/df_sample_unique_id_feature_fusion_20220206_20220227.pickle')\n",
    "# df_sample_unique_treatment = utils.load_pickle('data/no_secret_bt/df_sample_unique_treatment_feature_fusion_20220206_20220227.pickle')\n",
    "# df_sample_unique_y = utils.load_pickle('data/no_secret_bt/df_sample_unique_y_feature_fusion_20220206_20220227.pickle')\n",
    "# df_sample_unique_X = utils.load_pickle('data/no_secret_bt/df_sample_unique_X_feature_fusion_20220206_20220227.pickle')\n",
    "df_sample_unique_id = utils.load_pickle('data/no_secret_bt/df_sample_unique_id_feature_aspiration_20220206_20220227.pickle')\n",
    "df_sample_unique_treatment = utils.load_pickle('data/no_secret_bt/df_sample_unique_treatment_feature_aspiration_20220206_20220227.pickle')\n",
    "df_sample_unique_y = utils.load_pickle('data/no_secret_bt/df_sample_unique_y_feature_aspiration_20220206_20220227.pickle')\n",
    "df_sample_unique_X = utils.load_pickle('data/no_secret_bt/df_sample_unique_X_feature_aspiration_20220206_20220227.pickle')\n",
    "\n",
    "print(df_sample_unique_id.shape)\n",
    "print(df_sample_unique_treatment.shape)\n",
    "print(df_sample_unique_y.shape)\n",
    "print(df_sample_unique_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_unique_treatment_map = df_sample_unique_treatment.map({0.0: 'control', \n",
    "                                                                 0.2: 'treatment_1', \n",
    "                                                                 0.5: 'treatment_2', \n",
    "                                                                 1.0: 'treatment_3', \n",
    "                                                                 1.5: 'treatment_4', \n",
    "                                                                 1.8: 'treatment_5'})\n",
    "df_sample_unique_treatment_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(df_sample_unique_treatment_map, 'data/no_secret_bt/df_sample_unique_treatment_map_feature_fusion_20220206_20220227.pickle')\n",
    "utils.save_pickle(df_sample_unique_treatment_map, 'data/no_secret_bt/df_sample_unique_treatment_map_feature_aspiration_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample_unique_treatment_map = utils.load_pickle('data/no_secret_bt/df_sample_unique_treatment_map_feature_fusion_20220206_20220227.pickle')\n",
    "df_sample_unique_treatment_map = utils.load_pickle('data/no_secret_bt/df_sample_unique_treatment_map_feature_aspiration_20220206_20220227.pickle')\n",
    "df_sample_unique_treatment_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化倾向性得分（暂使用各treatment组占比（treatment+control），简单设置用于特征筛选）\n",
    "dict_p = {}\n",
    "dict_p['treatment_1'] = np.array([0.0713]*df_sample_unique_id.shape[0])\n",
    "dict_p['treatment_2'] = np.array([0.3092]*df_sample_unique_id.shape[0])\n",
    "dict_p['treatment_3'] = np.array([0.0750]*df_sample_unique_id.shape[0])\n",
    "dict_p['treatment_4'] = np.array([0.0587]*df_sample_unique_id.shape[0])\n",
    "dict_p['treatment_5'] = np.array([0.0467]*df_sample_unique_id.shape[0])\n",
    "dict_p"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.0    629307\n",
    "0.2     48304    0.0713\n",
    "0.5    281640    0.3092\n",
    "1.0     51025    0.0750\n",
    "1.5     39244    0.0587\n",
    "1.8     30853    0.0467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "30853 / (629307+30853)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(dict_p, 'data/no_secret_bt/pi/dict_p_feature_fusion_20220206_20220227.pickle')\n",
    "utils.save_pickle(dict_p, 'data/no_secret_bt/pi/dict_p_feature_aspiration_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_p = utils.load_pickle('data/no_secret_bt/pi/dict_p_20220206_20220227.pickle')\n",
    "dict_p = utils.load_pickle('data/no_secret_bt/pi/dict_p_feature_aspiration_20220206_20220227.pickle')\n",
    "dict_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# X-learner-lgb\n",
    "learner_x_lgb = BaseXClassifier(control_outcome_learner=lgb.LGBMClassifier(), \n",
    "                                treatment_outcome_learner=lgb.LGBMClassifier(), \n",
    "                                control_effect_learner=lgb.LGBMRegressor(), \n",
    "                                treatment_effect_learner=lgb.LGBMRegressor(), \n",
    "                                control_name='control')\n",
    "pred_x = learner_x_lgb.fit_predict(df_sample_unique_X.values, df_sample_unique_treatment_map.values, df_sample_unique_y.values, p=dict_p)\n",
    "# joblib.dump(learner_x_lgb, 'data/no_secret_bt/pi/estimator_pi_learner_x_lgb_feature_fusion_20220206_20220227.pickle')\n",
    "joblib.dump(learner_x_lgb, 'data/no_secret_bt/pi/estimator_pi_learner_x_lgb_feature_aspiration_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_auuc_x = pd.DataFrame({'model': ['X-learner-lgb']})\n",
    "for group in learner_x_lgb.t_groups:\n",
    "    print(group)\n",
    "    auuc = plot_all(cate=pred_x, treatment_groups=sorted(list(learner_x_lgb.t_groups)), treatment_test=df_sample_unique_treatment_map.values, \n",
    "                    y_test=df_sample_unique_y.values, cost_test=df_sample_unique_treatment.values, title='X-learner-LGB-p multi-treatment-{g} uplift curve'.format(g=group), \n",
    "                    select_treatment_group=group)\n",
    "    df_auuc_x['auuc_'+group] = [auuc]\n",
    "\n",
    "treatments_group_num = [48304, 281640, 51025, 39244, 30853]\n",
    "df_auuc_x['auuc_mean'] = df_auuc_x[[x for x in df_auuc_x.columns if x != 'model']].\\\n",
    "    agg(func=np.average, axis=1, weights=treatments_group_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auuc_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner_x_lgb = joblib.load('data/no_secret_bt/pi/estimator_pi_learner_x_lgb_feature_fusion_20220206_20220227.pickle')\n",
    "learner_x_lgb = joblib.load('data/no_secret_bt/pi/estimator_pi_learner_x_lgb_feature_aspiration_20220206_20220227.pickle')\n",
    "learner_x_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x = learner_x_lgb.predict(df_sample_unique_X.values, p=dict_p)\n",
    "pred_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(pred_x, 'data/no_secret_bt/pi/estimator_pi_learner_x_lgb_pred_feature_fusion_20220206_20220227.pickle')\n",
    "utils.save_pickle(pred_x, 'data/no_secret_bt/pi/estimator_pi_learner_x_lgb_pred_feature_aspiration_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_x = utils.load_pickle('data/no_secret_bt/pi/estimator_pi_learner_x_lgb_pred_feature_fusion_20220206_20220227.pickle')\n",
    "pred_x = utils.load_pickle('data/no_secret_bt/pi/estimator_pi_learner_x_lgb_pred_feature_aspiration_20220206_20220227.pickle')\n",
    "print(pred_x.shape)\n",
    "pred_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dict_feats_imp_pi = learner_x_lgb.get_importance(X=df_sample_unique_X.values, tau=pred_x, method='permutation')\n",
    "# utils.save_pickle(dict_feats_imp_pi, 'data/no_secret_bt/pi/pi_learner_x_lgb_feature_fusion_20220206_20220227.pickle')\n",
    "utils.save_pickle(dict_feats_imp_pi, 'data/no_secret_bt/pi/pi_learner_x_lgb_feature_aspiration_20220206_20220227.pickle')\n",
    "dict_feats_imp_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dict_feats_imp_pi = utils.load_pickle('data/no_secret_bt/pi/pi_learner_x_lgb_feature_fusion_20220206_20220227.pickle')\n",
    "dict_feats_imp_pi = utils.load_pickle('data/no_secret_bt/pi/pi_learner_x_lgb_feature_aspiration_20220206_20220227.pickle')\n",
    "dict_feats_imp_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pi = pd.DataFrame({'feature': list_feats_x_ht, \n",
    "                      'feature_index': ['Feature_{i}'.format(i=(str(x) if x>=100 else '0'+str(x) if x>=10 else '00'+str(x))) \n",
    "                                        for x in range(len(list_feats_x_ht))]\n",
    "                     })\n",
    "\n",
    "for x in sorted(list(dict_feats_imp_pi.keys())):\n",
    "    df_pi_tg = pd.DataFrame(dict_feats_imp_pi[x], columns=['permutation_importance_{}'.format(x)]).\\\n",
    "        reset_index().sort_values(by=['index'])\n",
    "    df_pi_tg.rename(columns={'index': 'feature_index'}, inplace=True)\n",
    "    df_pi = df_pi.merge(df_pi_tg, on='feature_index', how='left')\n",
    "\n",
    "treatments_group_num = [48304, 281640, 51025, 39244, 30853]\n",
    "df_pi['permutation_importance_mean'] = df_pi[[x for x in df_pi.columns if x not in ['feature', 'feature_index']]].\\\n",
    "    agg(func=np.average, axis=1, weights=treatments_group_num)\n",
    "df_pi.sort_values(by=['permutation_importance_mean'], ascending=[False], inplace=True)\n",
    "df_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pi[['permutation_importance_mean']].quantile([x/10 for x in range(11)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_pi_no_select = df_pi[(df_pi['permutation_importance_mean']<=0.0)]['feature'].values.tolist()\n",
    "print(len(list_feats_x_pi_no_select))\n",
    "list_feats_x_pi_no_select[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(list_feats_x_pi_no_select, 'data/no_secret_bt/list_feats/list_feats_x_pi_no_select_feature_fusion_20220206_20220227.pickle')\n",
    "utils.save_pickle(list_feats_x_pi_no_select, 'data/no_secret_bt/list_feats/list_feats_x_pi_no_select_feature_aspiration_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_pi = [x for x in list_feats_x_ht if x not in list_feats_x_pi_no_select]\n",
    "print(len(list_feats_x_pi))\n",
    "list_feats_x_pi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(list_feats_x_pi, 'data/no_secret_bt/list_feats/list_feats_x_pi_feature_fusion_20220206_20220227.pickle')\n",
    "utils.save_pickle(list_feats_x_pi, 'data/no_secret_bt/list_feats/list_feats_x_pi_feature_aspiration_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fusion\n",
    "list_feats_x_fusion = utils.load_pickle('data/no_secret_bt/list_feats/list_feats_x_pi_feature_fusion_20220206_20220227.pickle')\n",
    "print(len(list_feats_x_fusion))\n",
    "list_feats_x_fusion[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusion_all = utils.load_pickle('data/no_secret_bt/df_sample_label_feature_fusion_20220206_20220227.pickle')\n",
    "print(df_fusion_all.shape)\n",
    "df_fusion_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusion = df_fusion_all[['uid', 'obs_dt', 'coupon', 'label']+list_feats_x_fusion]\n",
    "print(df_fusion.shape)\n",
    "df_fusion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aspiration\n",
    "list_feats_x_aspiration = utils.load_pickle('data/no_secret_bt/list_feats/list_feats_x_pi_feature_aspiration_20220206_20220227.pickle')\n",
    "print(len(list_feats_x_aspiration))\n",
    "list_feats_x_aspiration[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aspiration_all = utils.load_pickle('data/no_secret_bt/df_sample_label_feature_aspiration_20220206_20220227.pickle')\n",
    "print(df_aspiration_all.shape)\n",
    "df_aspiration_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aspiration = df_aspiration_all[['uid', 'obs_dt', 'coupon', 'label']+list_feats_x_aspiration]\n",
    "print(df_aspiration.shape)\n",
    "df_aspiration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_union = df_fusion.merge(df_aspiration, on=['uid', 'obs_dt', 'coupon', 'label'], how='inner')\n",
    "print(df_union.shape)\n",
    "df_union.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union_des = utils.df_des(df_union)\n",
    "print(df_union_des.shape)\n",
    "df_union_des.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union_des[df_union_des['Miss Percent(%)']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_pickle(df_union, 'data/no_secret_bt/df_sample_label_feature_union_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_union = list_feats_x_fusion + list_feats_x_aspiration\n",
    "print(len(list_feats_x_union))\n",
    "list_feats_x_union[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_pickle(list_feats_x_union, 'data/no_secret_bt/list_feats/list_feats_x_feature_union_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_union = utils.load_pickle('data/no_secret_bt/df_sample_label_feature_union_20220206_20220227.pickle')\n",
    "print(df_union.shape)\n",
    "df_union.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_union = utils.load_pickle('data/no_secret_bt/list_feats/list_feats_x_feature_union_20220206_20220227.pickle')\n",
    "print(len(list_feats_x_union))\n",
    "list_feats_x_union[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id，treatment，X，y\n",
    "df_uid_obsDate = df_union[['uid', 'obs_dt']]\n",
    "df_treatment = df_union['coupon']\n",
    "df_y = df_union['label']\n",
    "df_X = df_union[list_feats_x_union]\n",
    "\n",
    "print(df_uid_obsDate.shape)\n",
    "print(df_treatment.shape)\n",
    "print(df_y.shape)\n",
    "print(df_X.shape)\n",
    "\n",
    "utils.save_pickle(df_uid_obsDate, 'data/no_secret_bt/df_sample_label_feature_union_uid_obsDate_20220206_20220227.pickle')\n",
    "utils.save_pickle(df_treatment, 'data/no_secret_bt/df_sample_label_feature_union_treatment_20220206_20220227.pickle')\n",
    "utils.save_pickle(df_y, 'data/no_secret_bt/df_sample_label_feature_union_y_20220206_20220227.pickle')\n",
    "utils.save_pickle(df_X, 'data/no_secret_bt/df_sample_label_feature_union_X_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uid_obsDate = utils.load_pickle('data/no_secret_bt/df_sample_label_feature_union_uid_obsDate_20220206_20220227.pickle')\n",
    "df_treatment = utils.load_pickle('data/no_secret_bt/df_sample_label_feature_union_treatment_20220206_20220227.pickle')\n",
    "df_y = utils.load_pickle('data/no_secret_bt/df_sample_label_feature_union_y_20220206_20220227.pickle')\n",
    "df_X = utils.load_pickle('data/no_secret_bt/df_sample_label_feature_union_X_20220206_20220227.pickle')\n",
    "\n",
    "print(df_uid_obsDate.shape)\n",
    "print(df_treatment.shape)\n",
    "print(df_y.shape)\n",
    "print(df_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treatment_map = df_treatment.map({0.0: 'control', \n",
    "                                     0.2: 'treatment_1', \n",
    "                                     0.5: 'treatment_2', \n",
    "                                     1.0: 'treatment_3', \n",
    "                                     1.5: 'treatment_4', \n",
    "                                     1.8: 'treatment_5'})\n",
    "df_treatment_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化倾向性得分（暂使用各treatment组占比（treatment+control），简单设置用于特征筛选）\n",
    "dict_p = {}\n",
    "dict_p['treatment_1'] = np.array([0.0713]*df_uid_obsDate.shape[0])\n",
    "dict_p['treatment_2'] = np.array([0.3092]*df_uid_obsDate.shape[0])\n",
    "dict_p['treatment_3'] = np.array([0.0750]*df_uid_obsDate.shape[0])\n",
    "dict_p['treatment_4'] = np.array([0.0587]*df_uid_obsDate.shape[0])\n",
    "dict_p['treatment_5'] = np.array([0.0467]*df_uid_obsDate.shape[0])\n",
    "dict_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# X-learner-LGB\n",
    "learner_x_lgb = BaseXClassifier(control_outcome_learner=lgb.LGBMClassifier(), \n",
    "                                treatment_outcome_learner=lgb.LGBMClassifier(), \n",
    "                                control_effect_learner=lgb.LGBMRegressor(), \n",
    "                                treatment_effect_learner=lgb.LGBMRegressor(), \n",
    "                                control_name='control')\n",
    "learner_x_lgb.fit(df_X.values, df_treatment_map.values, df_y.values, p=dict_p)\n",
    "joblib.dump(learner_x_lgb, 'data/model/no_secret_bt_20220206_20220227_union_all_XLearnerLgb.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_x_lgb = joblib.load('data/model/no_secret_bt_20220206_20220227_union_all_XLearnerLgb.pickle')\n",
    "learner_x_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x = learner_x_lgb.predict(df_X.values, p=dict_p)\n",
    "utils.save_pickle(pred_x, 'data/no_secret_bt/df_sample_label_feature_union_pred_20220206_20220227.pickle.pickle')\n",
    "pred_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_auuc_x = pd.DataFrame({'model': ['X-learner-lgb']})\n",
    "for group in learner_x_lgb.t_groups:\n",
    "    print(group)\n",
    "    auuc = plot_all(cate=pred_x, treatment_groups=sorted(list(learner_x_lgb.t_groups)), treatment_test=df_treatment_map.values, \n",
    "                    y_test=df_y.values, cost_test=df_treatment.values, title='X-learner-LGB-p multi-treatment-{g} uplift curve'.format(g=group), \n",
    "                    select_treatment_group=group)\n",
    "    df_auuc_x['auuc_'+group] = [auuc]\n",
    "\n",
    "treatments_group_num = [48304, 281640, 51025, 39244, 30853]\n",
    "df_auuc_x['auuc_mean'] = df_auuc_x[[x for x in df_auuc_x.columns if x != 'model']].\\\n",
    "    agg(func=np.average, axis=1, weights=treatments_group_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auuc_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = utils.load_pickle('data/no_secret_bt/df_sample_label_feature_union_X_20220206_20220227.pickle')\n",
    "pred_x = utils.load_pickle('data/no_secret_bt/df_sample_label_feature_union_pred_20220206_20220227.pickle')\n",
    "\n",
    "print(df_X.shape)\n",
    "print(pred_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_x_lgb = joblib.load('data/model/no_secret_bt_20220206_20220227_union_XleanerLgb.pickle')\n",
    "learner_x_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dict_feats_imp = learner_x_lgb.get_importance(X=df_X.values, tau=pred_x, method='permutation')\n",
    "utils.save_pickle(dict_feats_imp, 'data/no_secret_bt/feature_importance_union_20220206_20220227.pickle')\n",
    "dict_feats_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_union = utils.load_pickle('data/no_secret_bt/list_feats/list_feats_x_feature_union_20220206_20220227.pickle')\n",
    "print(len(list_feats_x_union))\n",
    "list_feats_x_union[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fi = pd.DataFrame({'feature': list_feats_x_union, \n",
    "                      'feature_index': ['Feature_{i}'.format(i=(str(x) if x>=100 else '0'+str(x) if x>=10 else '00'+str(x))) \n",
    "                                        for x in range(len(list_feats_x_union))]\n",
    "                     })\n",
    "\n",
    "for x in sorted(list(dict_feats_imp.keys())):\n",
    "    df_fi_tg = pd.DataFrame(dict_feats_imp[x], columns=['permutation_importance_{}'.format(x)]).\\\n",
    "        reset_index().sort_values(by=['index'])\n",
    "    df_fi_tg.rename(columns={'index': 'feature_index'}, inplace=True)\n",
    "    df_fi = df_fi.merge(df_fi_tg, on='feature_index', how='left')\n",
    "\n",
    "treatments_group_num = [48304, 281640, 51025, 39244, 30853]\n",
    "df_fi['permutation_importance_mean'] = df_fi[[x for x in df_fi.columns if x not in ['feature', 'feature_index']]].\\\n",
    "    agg(func=np.average, axis=1, weights=treatments_group_num)\n",
    "df_fi.sort_values(by=['permutation_importance_mean'], ascending=[False], inplace=True)\n",
    "df_fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fi[['permutation_importance_mean']].quantile([x/10 for x in range(11)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fi.to_csv('data/no_secret_bt/feature_importance_union_20220206_20220227_uplift.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['simhei']\n",
    "plt.rcParams['font.serif'] = ['simhei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style('darkgrid', {'font.sans-serif':['simhei', 'Droid Sans Fallback']})\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "fig, axes = plt.subplots(1, 1)\n",
    "sns.barplot(x='permutation_importance_mean', y='feature', data=df_fi.head(25), ax=axes)\n",
    "axes.set_title('Top-25 importance features')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fi[['feature', 'permutation_importance_mean']].head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fi = pd.read_csv('data/no_secret_bt/feature_importance_union_20220206_20220227_uplift.csv', encoding='utf-8')\n",
    "print(df_fi.shape)\n",
    "df_fi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_pi_no_select = df_fi[(df_fi['permutation_importance_mean']<0.00001)]['feature'].values.tolist()\n",
    "print(len(list_feats_x_pi_no_select))\n",
    "list_feats_x_pi_no_select[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_pickle(list_feats_x_pi_no_select, 'data/no_secret_bt/list_feats/list_feats_x_pi_no_select_feature_union_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_pi = [x for x in list_feats_x_union if x not in list_feats_x_pi_no_select]\n",
    "print(len(list_feats_x_pi))\n",
    "list_feats_x_pi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_pickle(list_feats_x_pi, 'data/no_secret_bt/list_feats/list_feats_x_pi_feature_union_20220206_20220227.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全量数据拉取sql处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_sql_coalesce(sql_file_path, special_words, sql_file_path_new):\n",
    "    with open(sql_file_path, 'r') as fi:\n",
    "        list_sql = fi.readlines()\n",
    "        \n",
    "        str_pattern = r'|'.join(['( '+x+', )' for x in special_words])\n",
    "        str_pattern_end = r'|'.join(['( '+x+' )' for x in special_words])\n",
    "        str_pattern_from = r'^from '\n",
    "        pattern = re.compile(str_pattern)\n",
    "        pattern_end = re.compile(str_pattern_end)\n",
    "        pattern_from = re.compile(str_pattern_from)\n",
    "        \n",
    "        list_sql_valid = []\n",
    "        list_sql_valid_front = []\n",
    "        list_sql_valid_back = []\n",
    "        \n",
    "        index_front = 0\n",
    "        for i in range(len(list_sql)):\n",
    "            if re.search(pattern_from, list_sql[i]):\n",
    "                index_front = i\n",
    "                break\n",
    "        list_sql_valid_back = list_sql[index_front+1:]\n",
    "        \n",
    "        try:\n",
    "            with tqdm(list(range(len(list_sql[:index_front])))) as t:\n",
    "                for i in t:\n",
    "                    if i == index_front - 1:\n",
    "                        if not re.search(str_pattern_end, list_sql[i]):\n",
    "                            list_sql_valid_front.append(list_sql[i])\n",
    "                    else:\n",
    "                        if not re.search(pattern, list_sql[i]):\n",
    "                            list_sql_valid_front.append(list_sql[i])\n",
    "        except KeyboardInterrupt:\n",
    "            t.close()\n",
    "            raise\n",
    "        t.close()\n",
    "        list_sql_valid = list_sql_valid_front + [list_sql[index_front]] + list_sql_valid_back\n",
    "        \n",
    "        with open(sql_file_path_new, 'w') as fo:\n",
    "            fo.writelines(list_sql_valid)\n",
    "            \n",
    "\n",
    "def del_sql_select_origin(sql_file_path, special_words, sql_file_path_new):\n",
    "    with open(sql_file_path, 'r') as fi:\n",
    "        list_sql = fi.readlines()\n",
    "        \n",
    "        str_pattern_1 = r'|'.join(['(\\t'+x+', )' for x in special_words])\n",
    "        str_pattern_2 = r'|'.join(['(    '+x+', )' for x in special_words])\n",
    "        str_pattern_3 = r'|'.join(['(\\t'+x+' )' for x in special_words])\n",
    "        str_pattern_4 = r'|'.join(['(    '+x+' )' for x in special_words])\n",
    "        str_pattern_from = r'^from '\n",
    "        pattern_1 = re.compile(str_pattern_1)\n",
    "        pattern_2 = re.compile(str_pattern_2)\n",
    "        pattern_3 = re.compile(str_pattern_3)\n",
    "        pattern_4 = re.compile(str_pattern_4)\n",
    "        pattern_from = re.compile(str_pattern_from)\n",
    "        \n",
    "        list_sql_valid = []\n",
    "        list_sql_valid_front = []\n",
    "        list_sql_valid_back = []\n",
    "        \n",
    "        index_front = 0\n",
    "        for i in range(len(list_sql)):\n",
    "            if re.search(pattern_from, list_sql[i]):\n",
    "                index_front = i\n",
    "                break\n",
    "        list_sql_valid_front = list_sql[:index_front]\n",
    "        \n",
    "        try:\n",
    "            with tqdm(list(range(len(list_sql[index_front+1:])))) as t:\n",
    "                for i in t:\n",
    "                    if not re.search(pattern_1, list_sql[index_front+1+i]) \\\n",
    "                        and not re.search(pattern_2, list_sql[index_front+1+i]) \\\n",
    "                        and not re.search(pattern_3, list_sql[index_front+1+i]) \\\n",
    "                        and not re.search(pattern_4, list_sql[index_front+1+i]):\n",
    "                        list_sql_valid_back.append(list_sql[index_front+1+i])\n",
    "        except KeyboardInterrupt:\n",
    "            t.close()\n",
    "            raise\n",
    "        t.close()\n",
    "        list_sql_valid = list_sql_valid_front + [list_sql[index_front]] + list_sql_valid_back\n",
    "        \n",
    "        with open(sql_file_path_new, 'w') as fo:\n",
    "            fo.writelines(list_sql_valid)\n",
    "            \n",
    "            \n",
    "def correct_end(sql_file_path, sql_file_path_new):\n",
    "    with open(sql_file_path, 'r') as fi:\n",
    "        list_sql = fi.readlines()\n",
    "        \n",
    "        str_pattern = r'from '\n",
    "        pattern = re.compile(str_pattern)\n",
    "        \n",
    "        try:\n",
    "            with tqdm(list(range(len(list_sql)))) as t:\n",
    "                for i in t:\n",
    "                    if re.search(pattern, list_sql[i]):\n",
    "                        if list_sql[i-1][-3:-1] == ', ':\n",
    "                            list_sql[i-1] = list_sql[i-1][:-3] + list_sql[i-1][-2:]\n",
    "        except KeyboardInterrupt:\n",
    "            t.close()\n",
    "            raise\n",
    "        t.close()\n",
    "        \n",
    "        with open(sql_file_path_new, 'w') as fo:\n",
    "            fo.writelines(list_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x = utils.load_pickle('data/no_secret_bt/list_feats/list_feats_x_pi_feature_union_20220206_20220227.pickle')\n",
    "print(len(list_feats_x))\n",
    "list_feats_x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_feats_x_all = utils.load_pickle('data/no_secret_bt/list_feats/list_feats_x_feature_fusion_20220206_20220227.pickle')\n",
    "list_feats_x_all = utils.load_pickle('data/no_secret_bt/list_feats/list_feats_x_feature_aspiration_20220206_20220227.pickle')\n",
    "print(len(list_feats_x_all))\n",
    "list_feats_x_all[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_del = [x for x in list_feats_x_all if x not in list_feats_x]\n",
    "print(len(list_feats_x_del))\n",
    "list_feats_x_del[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1821-1568"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4459-4123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "253+336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_file_path = 'sample_label_feature_fusion.sql'\n",
    "sql_file_path = 'sample_label_feature_aspiration.sql'\n",
    "special_words = list_feats_x_del\n",
    "# sql_file_path_new = 'sample_label_feature_fusion_new_uplift.sql'\n",
    "sql_file_path_new = 'sample_label_feature_aspiration_new_uplift.sql'\n",
    "\n",
    "del_sql_coalesce(sql_file_path, special_words, sql_file_path_new)\n",
    "del_sql_select_origin(sql_file_path_new, special_words, sql_file_path_new)\n",
    "correct_end(sql_file_path_new, sql_file_path_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepctr)",
   "language": "python",
   "name": "deepctr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
