{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad12366-e90a-422d-a018-c47f0aa8cdb3",
   "metadata": {},
   "source": [
    "# MMOE\n",
    "## 曝光 → 转化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a457bd-ccd6-44d6-b42b-c73e59a83997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import re\n",
    "import copy\n",
    "import torch\n",
    "import shap\n",
    "import utils.utils as util\n",
    "\n",
    "import utils_\n",
    "\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from model.mmoe_condition_2 import MMOE\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.dataset import DatasetLoader, DatasetLoader_w, DatasetLoader_www\n",
    "from utils.warmup_lr import GradualWarmupScheduler\n",
    "from loss.BCE_weighted_multi_task import BCEWL_weighted_multi_task\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('max_row', 500)\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas(desc='pandas bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596bd93-2c29-438e-983f-c9de659dd03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f96a1a-702c-4f7b-b7db-3dcf0d979f0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274daaff-cca6-4bd7-aed4-20fec6cc5bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_fusion = utils_.load_pickle('../data/exp2suc/')\n",
    "df_asp1 = utils_.load_pickle('../data/exp2suc/')\n",
    "df_asp2 = utils_.load_pickle('../data/exp2suc/')\n",
    "\n",
    "print(df_fusion.shape)\n",
    "print(df_asp1.shape)\n",
    "print(df_asp2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c4cec3-78b0-43a3-b3c1-0e82a8edff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_id_dt_item_y = ['uid', 'obs_dt', 'dt', 'item', 'table_type', 'label_apply', 'label_submit', 'label_pre_pass', 'label_pass', 'label_pass_1']\n",
    "\n",
    "list_feats_x_1 = [x for x in \n",
    "                  utils_.load_pickle('../data/exp2suc/list_feats/list_feats_x_fusion_pi_20230716_20231001.pickle') \n",
    "                  if x not in \n",
    "                  ['xxx']\n",
    "                 ]\n",
    "list_feats_x_2 = [x for x in \n",
    "                  utils_.load_pickle('../data/exp2suc/list_feats/list_feats_x_asp1_pi_20230716_20231001.pickle') \n",
    "                  if x not in \n",
    "                  []\n",
    "                 ]\n",
    "list_feats_x_3 = [x for x in \n",
    "                  utils_.load_pickle('../data/exp2suc/list_feats/list_feats_x_asp2_pi_20230716_20231001.pickle') \n",
    "                  if x not in \n",
    "                  []\n",
    "                 ]\n",
    "\n",
    "print(len(list_feats_x_1))\n",
    "print(len(list_feats_x_2))\n",
    "print(len(list_feats_x_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ed261-f711-4859-a6e4-dd6a7664f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_fusion[list_feats_id_dt_item_y+list_feats_x_1].\\\n",
    "    merge(df_asp1[list_feats_id_dt_item_y+list_feats_x_2]).\\\n",
    "    merge(df_asp2[list_feats_id_dt_item_y+list_feats_x_3])\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a3c71-c42e-4673-8ac2-98b2bfebee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_des = utils_.df_des(df)\n",
    "df_des.to_csv('../data/exp2suc/loss_pp_cb/', encoding='utf-8')\n",
    "\n",
    "df_des[df_des['Miss Percent(%)']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb438ec6-aab6-4f8f-931c-068570f9713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['item', 'table_type', 'uid']].groupby(by=['item', 'table_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f6a6b-5677-429e-a21a-05cf956af724",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_item = {\n",
    "    'aaa': 0, \n",
    "    'bbb': 1, \n",
    "    'ccc': 2, \n",
    "    'ddd': 3, \n",
    "    'eee': 4, \n",
    "    'fff': 5\n",
    "}\n",
    "\n",
    "df['item_id'] = df['item']\n",
    "df['item_id'].replace(dict_item, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d337b398-ddd0-40e2-acdb-f8e53d240882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['item', 'item_id', 'table_type', 'uid']].groupby(['item', 'item_id', 'table_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c0e6b2-bc17-46eb-aba7-ed7d729eeae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 物料\\表类型特征处理\n",
    "# one hot encoding\n",
    "list_feats_ohe = ['item_id', 'table_type']\n",
    "list_df_ohe = []\n",
    "try:\n",
    "    with tqdm(list_feats_ohe) as t:\n",
    "        for feat in t:\n",
    "            df_ohe_feat = utils_.one_hot_encoder(df, feat)\n",
    "            list_df_ohe.append(df_ohe_feat)\n",
    "except KeyboardInterrupt:\n",
    "    t.close()\n",
    "    raise\n",
    "t.close()\n",
    "\n",
    "df_ohe_part = pd.concat(list_df_ohe, axis=1)\n",
    "print(df_ohe_part.shape)\n",
    "df_ohe_part.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d2b71c-4153-4899-b780-8d5f1170d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = pd.concat([df, df_ohe_part], axis=1)\n",
    "print(df_ohe.shape)\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c127552-c2a1-4e72-8b70-110a9354c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_.save_pickle(df_ohe, '../data/exp2suc/loss_pp_cb/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f99e8-281d-4d4f-81ed-88fd95c38668",
   "metadata": {},
   "source": [
    "* 模型小物料 batch loss 权重调整（aa短表ys、小物料长表）\n",
    "* 6物料，aa、bb、cc、dd、ee、ff\n",
    "* fusion & aspiration；长表，“曝光→hpyk”特征；短表（aa），“曝光→ys通过”特征；761 维\n",
    "* 2023.07.16~2023.10.01\n",
    "* 训练验证集调整：\n",
    "  1. aa负样本（fqjj）下采样，线上打分需校准 ✅\n",
    "  2. cc负样本（fqjj）下采样，线上打分需校准 ✅\n",
    "  3. dd负样本（fqjj）下采样，线上打分需校准 ✅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba042173-407e-4d00-9c0a-1dd72a171420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = utils_.load_pickle('../data/exp2suc/df_pi_ohe_train_20230716_20231001.pickle')\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df488c67-0650-4632-ae16-1d971dba4104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集&验证集，8:2，80%\n",
    "df_train_train, df_train_eval = train_test_split(df_train, test_size=0.2, random_state=2023)\n",
    "print(df_train_train.shape)\n",
    "print(df_train_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571796b-dbf5-47e1-842b-8d9674c6b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_item_item = [x for x in \n",
    "                        df_train.columns \n",
    "                        if x.startswith('item_id_') \n",
    "                        and x not in \n",
    "                        []\n",
    "                       ]\n",
    "list_feats_item_table = [x for x in \n",
    "                         df_train.columns \n",
    "                         if x.startswith('table_type_') \n",
    "                         and x not in \n",
    "                         []\n",
    "                        ]\n",
    "list_feats_x_1 = [x for x in \n",
    "                  utils_.load_pickle('../data/exp2suc/list_feats/list_feats_x_fusion_pi_20230716_20231001_new.pickle') \n",
    "                  if x not in \n",
    "                  ['xxx']\n",
    "                 ]\n",
    "list_feats_x_2 = [x for x in \n",
    "                  utils_.load_pickle('../data/exp2suc/list_feats/list_feats_x_asp1_pi_20230716_20231001_new.pickle') \n",
    "                  if x not in \n",
    "                  []\n",
    "                 ]\n",
    "list_feats_x_3 = [x for x in \n",
    "                  utils_.load_pickle('../data/exp2suc/list_feats/list_feats_x_asp2_pi_20230716_20231001_new.pickle') \n",
    "                  if x not in \n",
    "                  []\n",
    "                 ]\n",
    "\n",
    "df_train_train_id = df_train_train[['uid', 'obs_dt', 'dt', 'item', 'item_id', 'table_type']]\n",
    "df_train_train_y = df_train_train[['label_apply', 'label_submit', 'label_pre_pass', 'label_pass', 'label_pass_1']]\n",
    "df_train_train_X = df_train_train[\n",
    "    list_feats_item_item+\n",
    "    list_feats_item_table+\n",
    "    list_feats_x_1+\n",
    "    list_feats_x_2+\n",
    "    list_feats_x_3\n",
    "]\n",
    "print(df_train_train_id.shape)\n",
    "print(df_train_train_y.shape)\n",
    "print(df_train_train_X.shape)\n",
    "\n",
    "df_train_eval_id = df_train_eval[['uid', 'obs_dt', 'dt', 'item', 'item_id', 'table_type']]\n",
    "df_train_eval_y = df_train_eval[['label_apply', 'label_submit', 'label_pre_pass', 'label_pass', 'label_pass_1']]\n",
    "df_train_eval_X = df_train_eval[\n",
    "    list_feats_item_item+\n",
    "    list_feats_item_table+\n",
    "    list_feats_x_1+\n",
    "    list_feats_x_2+\n",
    "    list_feats_x_3\n",
    "]\n",
    "print(df_train_eval_id.shape)\n",
    "print(df_train_eval_y.shape)\n",
    "print(df_train_eval_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b9b5c-3e56-4dd7-891c-149c45622229",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_.save_pickle(df_train_train_id, '../data/exp2suc/loss_pp_cb_feats/df_id_train_train_20230716_20231001.pickle')\n",
    "utils_.save_pickle(df_train_train_y, '../data/exp2suc/loss_pp_cb_feats/df_y_train_train_20230716_20231001.pickle')\n",
    "utils_.save_pickle(df_train_train_X, '../data/exp2suc/loss_pp_cb_feats/df_X_pi_train_train_20230716_20231001.pickle')\n",
    "\n",
    "utils_.save_pickle(df_train_eval_id, '../data/exp2suc/loss_pp_cb_feats/df_id_train_eval_20230716_20231001.pickle')\n",
    "utils_.save_pickle(df_train_eval_y, '../data/exp2suc/loss_pp_cb_feats/df_y_train_eval_20230716_20231001.pickle')\n",
    "utils_.save_pickle(df_train_eval_X, '../data/exp2suc/loss_pp_cb_feats/df_X_pi_train_eval_20230716_20231001.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925e7863-3546-44c7-9d73-04f3da953e14",
   "metadata": {},
   "source": [
    "## 入参处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20526303-f459-4809-a84b-d3eb349a622a",
   "metadata": {},
   "source": [
    "* 训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc319d-04f0-43e4-93f6-1e16c4575e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_train_id = utils_.load_pickle('../data/exp2suc/loss_pp_cb/df_id_train_train_20230716_20231001.pickle')\n",
    "# df_train_train_y = utils_.load_pickle('../data/exp2suc/loss_pp_cb/df_y_train_train_20230716_20231001.pickle')\n",
    "# df_train_train_X = utils_.load_pickle('../data/exp2suc/loss_pp_cb/df_X_pi_train_train_20230716_20231001.pickle')\n",
    "\n",
    "df_train_train_id = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/df_id_train_train_20230716_20231001.pickle')\n",
    "df_train_train_y = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/df_y_train_train_20230716_20231001.pickle')\n",
    "df_train_train_X = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/df_X_pi_train_train_20230716_20231001.pickle')\n",
    "\n",
    "print(df_train_train_id.shape)\n",
    "print(df_train_train_y.shape)\n",
    "print(df_train_train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76329d7a-688a-4b4b-ae0d-4dd5b6d30bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_feats_item = ['item_id_{}'.format(x) for x in range(6)]\n",
    "\n",
    "condition_feats_table = ['table_type_{}'.format(x) for x in range(1, 3)]\n",
    "\n",
    "sparse_feats = [\n",
    "    'xxx'\n",
    "]\n",
    "sparse_feats = [x for x in df_train_train_X.columns if x in sparse_feats]\n",
    "\n",
    "dense_feats = [x for x in df_train_train_X.columns \n",
    "               if x not in condition_feats_item+condition_feats_table+sparse_feats]\n",
    "\n",
    "print(len(condition_feats_item))\n",
    "print(len(condition_feats_table))\n",
    "print(len(sparse_feats))\n",
    "print(len(dense_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7370b45-5f06-40d7-80db-dc8865b52a69",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in sparse_feats:\n",
    "    print('{}:{}'.format(x, df_train_train_X[x].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc87f82b-89be-4b13-be00-879f31706695",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sparse_feats = [x for x in sparse_feats if df_train_train_X[x].nunique()<=32 \n",
    "                and x not in ['xxx']]\n",
    "print(len(sparse_feats))\n",
    "sparse_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e3a092-0e1f-4bf9-a2a9-277a0793a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_feats = [x for x in df_train_train_X.columns \n",
    "               if x not in condition_feats_item+condition_feats_table+sparse_feats]\n",
    "print(len(dense_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0148a8c6-d90a-4d7a-86be-12ae1a2cd3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils_.save_pickle(condition_feats_item, '../data/exp2suc/loss_pp_cb/list_condition_feats_item.pickle')\n",
    "# utils_.save_pickle(condition_feats_table, '../data/exp2suc/loss_pp_cb/list_condition_feats_table.pickle')\n",
    "# utils_.save_pickle(sparse_feats, '../data/exp2suc/loss_pp_cb/list_sparse_feats.pickle')\n",
    "# utils_.save_pickle(dense_feats, '../data/exp2suc/loss_pp_cb/list_dense_feats.pickle')\n",
    "\n",
    "utils_.save_pickle(condition_feats_item, '../data/exp2suc/loss_pp_cb_feats/list_condition_feats_item.pickle')\n",
    "utils_.save_pickle(condition_feats_table, '../data/exp2suc/loss_pp_cb_feats/list_condition_feats_table.pickle')\n",
    "utils_.save_pickle(sparse_feats, '../data/exp2suc/loss_pp_cb_feats/list_sparse_feats.pickle')\n",
    "utils_.save_pickle(dense_feats, '../data/exp2suc/loss_pp_cb_feats/list_dense_feats.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d52c9e8-2ad9-49d5-8c40-b0879b237c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连续\n",
    "ss = StandardScaler()\n",
    "X_train_train_dense_ss = ss.fit_transform(df_train_train_X[dense_feats])\n",
    "\n",
    "# joblib.dump(ss, '../data/exp2suc/loss_pp_cb/ss.pickle')\n",
    "joblib.dump(ss, '../data/exp2suc/loss_pp_cb_feats/ss.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313693fc-bf64-4354-aee6-cfe8408e32a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train_train_dense = pd.DataFrame(X_train_train_dense_ss, columns=dense_feats)\n",
    "print(df_X_train_train_dense.shape)\n",
    "df_X_train_train_dense.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1254c55e-df2e-402a-a7d8-af7361d7ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 离散\n",
    "dict_lbe = {}\n",
    "list_X_train_train_sparse = []\n",
    "\n",
    "try:\n",
    "    with tqdm(sparse_feats) as t:\n",
    "        for x in t:\n",
    "            lbe = LabelEncoder()\n",
    "            df_X_sparse_each = pd.DataFrame(lbe.fit_transform(df_train_train_X[x]), columns=[x])\n",
    "            dict_lbe[x] = lbe\n",
    "            list_X_train_train_sparse.append(df_X_sparse_each)\n",
    "except KeyboardInterrupt:\n",
    "    t.close()\n",
    "    raise\n",
    "t.close()\n",
    "\n",
    "# joblib.dump(dict_lbe, '../data/exp2suc/loss_pp_cb/dict_lbe.pickle')\n",
    "joblib.dump(dict_lbe, '../data/exp2suc/loss_pp_cb_feats/dict_lbe.pickle')\n",
    "\n",
    "df_X_train_train_sparse = pd.concat(list_X_train_train_sparse, axis=1)\n",
    "print(df_X_train_train_sparse.shape)\n",
    "df_X_train_train_sparse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15348da8-6bca-4677-b7d3-089d693451ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并\n",
    "df_train_train_X_condition_item = df_train_train_X[condition_feats_item].reset_index(drop=True)\n",
    "df_train_train_X_condition_table = df_train_train_X[condition_feats_table].reset_index(drop=True)\n",
    "df_train_train_X_transform = pd.concat([df_train_train_X_condition_item, df_train_train_X_condition_table, \n",
    "                                        df_X_train_train_sparse, df_X_train_train_dense], axis=1)\n",
    "print(df_train_train_X_transform.shape)\n",
    "df_train_train_X_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814d82b2-04a9-4b40-a4e5-95af479b9e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c657a0a5-5823-4867-a25f-f84edbbc9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_train_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e2ec9-d379-4b92-8569-769b783d0153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils_.save_pickle(df_train_train_X_transform, '../data/exp2suc/loss_pp_cb/df_X_pi_train_train_transform_20230716_20231001.pickle')\n",
    "utils_.save_pickle(df_train_train_X_transform, '../data/exp2suc/loss_pp_cb_feats/df_X_pi_train_train_transform_20230716_20231001.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb2338e-604b-40c3-a1e1-354b555980b2",
   "metadata": {},
   "source": [
    "* 验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691eb79b-46fe-4c6e-8e6e-b14e976b5695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_eval_id = utils_.load_pickle('../data/exp2suc/loss_pp_cb/df_id_train_eval_20230716_20231001.pickle')\n",
    "# df_train_eval_y = utils_.load_pickle('../data/exp2suc/loss_pp_cb/df_y_train_eval_20230716_20231001.pickle')\n",
    "# df_train_eval_X = utils_.load_pickle('../data/exp2suc/loss_pp_cb/df_X_pi_train_eval_20230716_20231001.pickle')\n",
    "\n",
    "df_train_eval_id = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/df_id_train_eval_20230716_20231001.pickle')\n",
    "df_train_eval_y = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/df_y_train_eval_20230716_20231001.pickle')\n",
    "df_train_eval_X = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/df_X_pi_train_eval_20230716_20231001.pickle')\n",
    "\n",
    "print(df_train_eval_id.shape)\n",
    "print(df_train_eval_y.shape)\n",
    "print(df_train_eval_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f79217-0475-443b-9a76-5416f694203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition_feats_item = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_condition_feats_item.pickle')\n",
    "# condition_feats_table = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_condition_feats_table.pickle')\n",
    "# sparse_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_sparse_feats.pickle')\n",
    "# dense_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_dense_feats.pickle')\n",
    "\n",
    "condition_feats_item = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_condition_feats_item.pickle')\n",
    "condition_feats_table = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_condition_feats_table.pickle')\n",
    "sparse_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_sparse_feats.pickle')\n",
    "dense_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_dense_feats.pickle')\n",
    "\n",
    "print(len(condition_feats_item))\n",
    "print(len(condition_feats_table))\n",
    "print(len(sparse_feats))\n",
    "print(len(dense_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e49c5b-57cd-4b00-ae9d-4939c724aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连续\n",
    "# ss = joblib.load('../data/exp2suc/loss_pp_cb/ss.pickle')\n",
    "ss = joblib.load('../data/exp2suc/loss_pp_cb_feats/ss.pickle')\n",
    "\n",
    "X_train_eval_dense_ss = ss.transform(df_train_eval_X[dense_feats])\n",
    "print(X_train_eval_dense_ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39069bd0-aae6-4e23-8455-9c54af045438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train_eval_dense_ss = pd.DataFrame(X_train_eval_dense_ss, columns=dense_feats)\n",
    "print(df_X_train_eval_dense_ss.shape)\n",
    "df_X_train_eval_dense_ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04db3d6-a8cc-4aff-b89e-76a051f02636",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 离散\n",
    "# dict_lbe = joblib.load('../data/exp2suc/loss_pp_cb/dict_lbe.pickle')\n",
    "dict_lbe = joblib.load('../data/exp2suc/loss_pp_cb_feats/dict_lbe.pickle')\n",
    "\n",
    "for x in sparse_feats:\n",
    "    print(x, dict_lbe[x].classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07a6c1f-12d1-49fb-a792-9869e510209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_X_sparse = []\n",
    "\n",
    "try:\n",
    "    with tqdm(sparse_feats) as t:\n",
    "        for x in t:\n",
    "            list_feat_values_unseen = list(set(df_train_eval_X[x].unique())-set(dict_lbe[x].classes_))\n",
    "            if len(list_feat_values_unseen) > 0:\n",
    "                print(x)\n",
    "                df_train_eval_X[x].replace(list_feat_values_unseen, -1, inplace=True)\n",
    "            df_train_eval_X_sparse_each = pd.DataFrame(dict_lbe[x].transform(df_train_eval_X[x]), columns=[x])\n",
    "            list_X_sparse.append(df_train_eval_X_sparse_each)\n",
    "except KeyboardInterrupt:\n",
    "    t.close()\n",
    "    raise\n",
    "t.close()\n",
    "\n",
    "df_X_train_eval_sparse = pd.concat(list_X_sparse, axis=1)\n",
    "print(df_X_train_eval_sparse.shape)\n",
    "df_X_train_eval_sparse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625032f-0f5b-405a-aaed-f6307ae80871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并\n",
    "df_train_eval_X_condition_item = df_train_eval_X[condition_feats_item].reset_index(drop=True)\n",
    "df_train_eval_X_condition_table = df_train_eval_X[condition_feats_table].reset_index(drop=True)\n",
    "df_train_eval_X_transform = pd.concat([df_train_eval_X_condition_item, df_train_eval_X_condition_table, \n",
    "                                       df_X_train_eval_sparse, df_X_train_eval_dense_ss], axis=1)\n",
    "print(df_train_eval_X_transform.shape)\n",
    "df_train_eval_X_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eaa5c9-78d6-4600-9723-d85e61f01ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_eval_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b34b50-fe3a-4798-ae92-0b6ef834e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_eval_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1275ae0d-c598-47d5-a904-3684533d883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils_.save_pickle(df_train_eval_X_transform, '../data/exp2suc/loss_pp_cb/df_X_pi_train_eval_transform_20230716_20231001.pickle')\n",
    "utils_.save_pickle(df_train_eval_X_transform, '../data/exp2suc/loss_pp_cb_feats/df_X_pi_train_eval_transform_20230716_20231001.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ff9c0-35f0-489c-8e06-d34d90774eb2",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c40051-138d-4b80-a585-186561450d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_X_train_train_transform = utils_.load_pickle('../data/exp2suc/loss_pp_cb/df_X_pi_train_train_transform_20230716_20231001.pickle')\n",
    "df_X_train_train_transform = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/df_X_pi_train_train_transform_20230716_20231001.pickle')\n",
    "\n",
    "print(df_X_train_train_transform.shape)\n",
    "df_X_train_train_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce137251-1ab0-44fa-9090-f8299a66f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition_feats_item = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_condition_feats_item.pickle')\n",
    "# condition_feats_table = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_condition_feats_table.pickle')\n",
    "# sparse_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_sparse_feats.pickle')\n",
    "# dense_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_dense_feats.pickle')\n",
    "\n",
    "condition_feats_item = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_condition_feats_item.pickle')\n",
    "condition_feats_table = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_condition_feats_table.pickle')\n",
    "sparse_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_sparse_feats.pickle')\n",
    "dense_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_dense_feats.pickle')\n",
    "\n",
    "print(len(condition_feats_item))\n",
    "print(len(condition_feats_table))\n",
    "print(len(sparse_feats))\n",
    "print(len(dense_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a529e2c2-3b40-49b8-a656-d5a00a89412b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "feats_columns = [[util.denseFeature(feat) for feat in condition_feats_item]] + \\\n",
    "                [[util.denseFeature(feat) for feat in condition_feats_table]] + \\\n",
    "                [[util.sparseFeature(x, int(df_X_train_train_transform[x].max()+1), 4) for x in sparse_feats]] + \\\n",
    "                [[util.denseFeature(feat) for feat in dense_feats]]\n",
    "feats_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e505125-8fb1-48e7-a4e3-2a7914073033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils_.save_pickle(feats_columns, '../data/exp2suc/loss_pp_cb/feats_columns.pickle')\n",
    "utils_.save_pickle(feats_columns, '../data/exp2suc/loss_pp_cb_feats/feats_columns.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3be93e-7a1e-4709-a297-fb1d8bf9ba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_X_train_train_transform = utils_.load_pickle('../data/exp2suc/loss_pp_cb/df_X_pi_train_train_transform_20230716_20231001.pickle')\n",
    "# df_y_train_train = utils_.load_pickle('../data/exp2suc/loss_pp_cb/df_y_train_train_20230716_20231001.pickle')\n",
    "\n",
    "# df_X_train_eval_transform = utils_.load_pickle('../data/exp2suc/loss_pp_cb/df_X_pi_train_eval_transform_20230716_20231001.pickle')\n",
    "# df_y_train_eval = utils_.load_pickle('../data/exp2suc/loss_pp_cb/df_y_train_eval_20230716_20231001.pickle')\n",
    "\n",
    "df_X_train_train_transform = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/df_X_pi_train_train_transform_20230716_20231001.pickle')\n",
    "df_y_train_train = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/df_y_train_train_20230716_20231001.pickle')\n",
    "\n",
    "df_X_train_eval_transform = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/df_X_pi_train_eval_transform_20230716_20231001.pickle')\n",
    "df_y_train_eval = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/df_y_train_eval_20230716_20231001.pickle')\n",
    "\n",
    "print(df_X_train_train_transform.shape)\n",
    "print(df_y_train_train.shape)\n",
    "\n",
    "print(df_X_train_eval_transform.shape)\n",
    "print(df_y_train_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e33cda-e632-4cd4-ae91-0d8793f86054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置样本权重\n",
    "# 小物料，前链路（fqjj、tjjj），小物料:其他=1:5\n",
    "w_pre_link_train_train = df_X_train_train_transform[['item_id_4', 'item_id_5']].max(axis=1)\n",
    "w_pre_link_train_train = w_pre_link_train_train.apply(lambda x: 5 if x == 0 else 1)\n",
    "\n",
    "w_pre_link_train_eval = df_X_train_eval_transform[['item_id_4', 'item_id_5']].max(axis=1)\n",
    "w_pre_link_train_eval = w_pre_link_train_eval.apply(lambda x: 5 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0468ee6f-1bd7-44c7-8e04-aae13b6627a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_pre_link_train_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29408f70-750b-44d8-8eaf-08cf44b4a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_pre_link_train_eval.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f5c61e-ab6e-419b-9074-ca6ac659e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa短表，ys通过，aa短表:其他=10:1\n",
    "w_gf_pp_train_train = df_X_train_train_transform[['item_id_0', 'table_type_1']].sum(axis=1)\n",
    "w_gf_pp_train_train = w_gf_pp_train_train.apply(lambda x: 10 if x == 2 else 1)\n",
    "\n",
    "w_gf_pp_train_eval = df_X_train_eval_transform[['item_id_0', 'table_type_1']].sum(axis=1)\n",
    "w_gf_pp_train_eval = w_gf_pp_train_eval.apply(lambda x: 10 if x == 2 else 1)\n",
    "\n",
    "# aa短表，ys通过，aa短表:其他=1:0\n",
    "# w_gf_pp_train_train = df_X_train_train_transform[['item_id_0', 'table_type_1']].sum(axis=1)\n",
    "# w_gf_pp_train_train = w_gf_pp_train_train.apply(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "# w_gf_pp_train_eval = df_X_train_eval_transform[['item_id_0', 'table_type_1']].sum(axis=1)\n",
    "# w_gf_pp_train_eval = w_gf_pp_train_eval.apply(lambda x: 1 if x == 2 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1b3ec5-e314-49b7-9bf3-fb68893e727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gf_pp_train_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b6406-9ef7-4727-b7e3-88f64555595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_gf_pp_train_eval.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b282f06b-ac3c-4e4e-a722-f5bdb522b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 长表&小物料，后链路（hp、hpyk），aa短表:小物料:其他=1:2:10\n",
    "w_after_link_train_train = df_X_train_train_transform[['item_id_0', 'item_id_4', 'item_id_5', 'table_type_1']].\\\n",
    "    apply(lambda x: 1 if x['item_id_0']==1 and x['table_type_1']==1 \n",
    "                      else 2 if x['item_id_4']==1 or x['item_id_5']==1 \n",
    "                             else 10, \n",
    "          axis=1)\n",
    "\n",
    "w_after_link_train_eval = df_X_train_eval_transform[['item_id_0', 'item_id_4', 'item_id_5', 'table_type_1']].\\\n",
    "    apply(lambda x: 1 if x['item_id_0']==1 and x['table_type_1']==1 \n",
    "                      else 2 if x['item_id_4']==1 or x['item_id_5']==1 \n",
    "                             else 10, \n",
    "          axis=1)\n",
    "\n",
    "# 长表&小物料，后链路（hp、hpyk），aa短表:小物料:其他=0:1:5\n",
    "# w_after_link_train_train = df_X_train_train_transform[['item_id_0', 'item_id_4', 'item_id_5', 'table_type_1']].\\\n",
    "#     apply(lambda x: 0 if x['item_id_0']==1 and x['table_type_1']==1 \n",
    "#                       else 1 if x['item_id_4']==1 or x['item_id_5']==1 \n",
    "#                              else 5, \n",
    "#           axis=1)\n",
    "\n",
    "# w_after_link_train_eval = df_X_train_eval_transform[['item_id_0', 'item_id_4', 'item_id_5', 'table_type_1']].\\\n",
    "#     apply(lambda x: 0 if x['item_id_0']==1 and x['table_type_1']==1 \n",
    "#                       else 1 if x['item_id_4']==1 or x['item_id_5']==1 \n",
    "#                              else 5, \n",
    "#           axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164fe540-79c2-425c-8000-63224a80091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_after_link_train_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ae04f-3127-418e-a362-7f18b29ef38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_after_link_train_eval.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4cd225-4745-426f-915f-908efec134ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "logger = util.get_logger('')\n",
    "util.seed_everything(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ca284-dd7c-4c3c-b08a-d6d238a12eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    DatasetLoader_www(df_X_train_train_transform.values, df_y_train_train.values, \n",
    "                      w_pre_link_train_train.values, w_gf_pp_train_train.values, w_after_link_train_train.values), \n",
    "    1024, shuffle=False, num_workers=8)\n",
    "eval_loader = DataLoader(\n",
    "    DatasetLoader_www(df_X_train_eval_transform.values, df_y_train_eval.values, \n",
    "                      w_pre_link_train_eval.values, w_gf_pp_train_eval.values, w_after_link_train_eval.values), \n",
    "    1024, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb04318-7b32-4fbb-b039-e2e5317a46e9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'Model': {\n",
    "        'num_experts': 7, \n",
    "        'expert_hidden_units': [512, 256, 128], \n",
    "        'units': 64, \n",
    "        'num_tasks': 5, \n",
    "        'tower_hidden_units': [64, 32, 16], \n",
    "        'dropout': 0.5, \n",
    "        'use_bn': False\n",
    "    }\n",
    "}\n",
    "\n",
    "# feats_columns = utils_.load_pickle('../data/exp2suc/loss_pp_cb/feats_columns.pickle')\n",
    "feats_columns = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/feats_columns.pickle')\n",
    "\n",
    "model = MMOE(config, feats_columns).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66ff476-6105-4bc5-91ec-e94781973b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "(819*512+512*256+256*128+128*64)*7+819*7*5+(72*64+64*32+32*16+16*1)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feb168d-0422-4fe7-a394-d114868df51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.modules():\n",
    "    if isinstance(m, (torch.nn.Conv2d, torch.nn.Linear)):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        # nn.init.kaiming_uniform_(m.weight)\n",
    "    elif isinstance(m, torch.nn.BatchNorm1d):\n",
    "        torch.nn.init.constant_(m.weight, 1)\n",
    "        torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fed973-653d-412a-9e9e-00728ae5ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, eval_loader, model, optimizer, scheduler, criterion, epochs, data_eval, file):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            x, y = x.to(device).to(torch.float32), y.to(device).to(torch.float32)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            list_loss = [criterion[j](output[:, j], y[:, j]) for j in range(len(criterion))]\n",
    "            # list_loss = [criterion[j](output[:, j], y[:, j]) for j in range(len(criterion)-1)] + \\\n",
    "            #     [10*criterion[-1](output[:, -1], y[:, -1])]\n",
    "            loss = reduce(lambda x, y: x+y, list_loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            if i % 100 == 0:\n",
    "                str_loss = ', '.join(['loss{}: {:.6f}'.format(j, x.item()) for j, x in enumerate(list_loss)]) + ', loss: {:.6f}'.format(loss.item())\n",
    "                logger.info('Epoch: [{}/{}], Step: [{}/{}], Lr: {:.6f}, '.format(\n",
    "                    epoch+1, epochs, i+1, len(train_loader), optimizer.param_groups[0]['lr'])+str_loss)\n",
    "        \n",
    "        val(eval_loader, model, criterion, data_eval, file)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "def train_loss(train_loader, eval_loader, model, optimizer, scheduler, criterion_train, criterion_eval, epochs, data_eval, file):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for i, (x, y, w1, w2, w3) in enumerate(train_loader):\n",
    "            x, y = x.to(device).to(torch.float32), y.to(device).to(torch.float32)\n",
    "            w1, w2, w3 = w1.to(device).to(torch.float32), w2.to(device).to(torch.float32), w3.to(device).to(torch.float32)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            list_loss = [criterion_train[j](output[:, j], y[:, j], w1) for j in [0, 1]] + \\\n",
    "                [criterion_train[2](output[:, 2], y[:, 2], w2)] + \\\n",
    "                [criterion_train[j](output[:, j], y[:, j], w3) for j in [3, 4]]\n",
    "            loss = reduce(lambda x, y: x+y, list_loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            if i % 100 == 0:\n",
    "                str_loss = ', '.join(['loss{}: {:.6f}'.format(j, x.item()) for j, x in enumerate(list_loss)]) + ', loss: {:.6f}'.format(loss.item())\n",
    "                logger.info('Epoch: [{}/{}], Step: [{}/{}], Lr: {:.6f}, '.format(\n",
    "                    epoch+1, epochs, i+1, len(train_loader), optimizer.param_groups[0]['lr'])+str_loss)\n",
    "        \n",
    "        val_loss(eval_loader, model, criterion_eval, data_eval, file)\n",
    "        \n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeee586-4769-42dd-8774-a49f9136f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(eval_loader, model, criterion, data_eval, file):\n",
    "    model.eval()\n",
    "    \n",
    "    global best_loss\n",
    "    global best_auc\n",
    "    y_true = data_eval[1]\n",
    "    num_class = y_true.shape[1]\n",
    "    \n",
    "    eval_loss = 0\n",
    "    list_eval_loss = [0] * num_class\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(eval_loader):\n",
    "            x, y = x.to(device).to(torch.float32), y.to(device).to(torch.float32)\n",
    "            output = model(x)\n",
    "            list_eval_loss = [x+criterion[j](output[:, j], y[:, j]).item() for j, x in enumerate(list_eval_loss)]\n",
    "            eval_loss = sum(list_eval_loss)\n",
    "            \n",
    "            output1 = torch.sigmoid(output)\n",
    "            if i == 0:\n",
    "                y_pred = output1.cpu().numpy()\n",
    "            else:\n",
    "                y_pred = np.concatenate((y_pred, output1.cpu().numpy()), axis=0)\n",
    "    \n",
    "    list_eval_loss = [x/len(eval_loader) for x in list_eval_loss]\n",
    "    eval_loss /= len(eval_loader)\n",
    "    \n",
    "    eval_auc = [util.auc(y_true[:, i], y_pred[:, i]) for i in range(num_class)]\n",
    "    str_auc = ', '.join(['AUC{}: {:.6f}'.format(i, eval_auc[i]) for i in range(num_class)])\n",
    "    str_loss = 'Eval set: Average loss: {:.6f}, '.format(eval_loss) + ', '.join(['Average loss{}: {:.6f}'.format(j, x) for j, x in enumerate(list_eval_loss)])\n",
    "    \n",
    "    logger.info('{}, {}'.format(str_loss, str_auc))\n",
    "    \n",
    "    if list_eval_loss[-1] < best_loss: # 只关注链路尾部输出\n",
    "        best_loss = list_eval_loss[-1]\n",
    "        torch.save(model.state_dict(), './save/{}.pth'.format(file))\n",
    "        model1 = torch.jit.script(model)\n",
    "        torch.jit.save(model1, './save/{}.pt'.format(file))\n",
    "        logger.info('Save model with loss: {:.6f}, {}'.format(best_loss, str_auc))\n",
    "        \n",
    "\n",
    "def val_loss(eval_loader, model, criterion, data_eval, file):\n",
    "    model.eval()\n",
    "    \n",
    "    global best_loss\n",
    "    global best_auc\n",
    "    y_true = data_eval[1]\n",
    "    num_class = y_true.shape[1]\n",
    "    \n",
    "    eval_loss = 0\n",
    "    list_eval_loss = [0] * num_class\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (x, y, w1, w2, w3) in enumerate(eval_loader):\n",
    "            x, y = x.to(device).to(torch.float32), y.to(device).to(torch.float32)\n",
    "            w1, w2, w3 = w1.to(device).to(torch.float32), w2.to(device).to(torch.float32), w3.to(device).to(torch.float32)\n",
    "            output = model(x)\n",
    "            # list_eval_loss = [x+criterion[j](output[:, j], y[:, j], w1).item() for j, x in enumerate(list_eval_loss[:2])] + \\\n",
    "            #     [list_eval_loss[2]+criterion[2](output[:, 2], y[:, 2], w2).item()] + \\\n",
    "            #     [x+criterion[j](output[:, j], y[:, j], w3).item() for j, x in enumerate(list_eval_loss[3:])]\n",
    "            list_eval_loss = [x+criterion[j](output[:, j], y[:, j]).item() for j, x in enumerate(list_eval_loss)]\n",
    "            eval_loss = sum(list_eval_loss)\n",
    "            \n",
    "            output1 = torch.sigmoid(output)\n",
    "            if i == 0:\n",
    "                y_pred = output1.cpu().numpy()\n",
    "            else:\n",
    "                y_pred = np.concatenate((y_pred, output1.cpu().numpy()), axis=0)\n",
    "    \n",
    "    list_eval_loss = [x/len(eval_loader) for x in list_eval_loss]\n",
    "    eval_loss /= len(eval_loader)\n",
    "    \n",
    "    eval_auc = [util.auc(y_true[:, i], y_pred[:, i]) for i in range(num_class)]\n",
    "    str_auc = ', '.join(['AUC{}: {:.6f}'.format(i, eval_auc[i]) for i in range(num_class)])\n",
    "    str_loss = 'Eval set: Average loss: {:.6f}, '.format(eval_loss) + ', '.join(['Average loss{}: {:.6f}'.format(j, x) for j, x in enumerate(list_eval_loss)])\n",
    "    \n",
    "    logger.info('{}, {}'.format(str_loss, str_auc))\n",
    "    \n",
    "    if list_eval_loss[2] + list_eval_loss[-1] < best_loss: # 关注链路特定位置的输出\n",
    "        best_loss = list_eval_loss[2] + list_eval_loss[-1] # label_pre_pass, label_pass_1\n",
    "        torch.save(model.state_dict(), './save/{}.pth'.format(file))\n",
    "        model1 = torch.jit.script(model)\n",
    "        torch.jit.save(model1, './save/{}.pt'.format(file))\n",
    "        logger.info('Save model with loss: {:.6f}, {}'.format(best_loss, str_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8984c96-651f-46c3-8f73-45965ddb3a30",
   "metadata": {},
   "source": [
    "* 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0f2a3-2489-4daf-8f62-6b4ab7abd0a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion_train = (BCEWL_weighted_multi_task().to(device), BCEWL_weighted_multi_task().to(device), BCEWL_weighted_multi_task().to(device), BCEWL_weighted_multi_task().to(device), BCEWL_weighted_multi_task().to(device))\n",
    "criterion_eval = (torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20, 30, 40], gamma=0.1)\n",
    "# scheduler_wu = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=5, after_scheduler=scheduler_ms)\n",
    "\n",
    "best_loss = np.inf\n",
    "best_auc = 0\n",
    "\n",
    "# train_loss(train_loader, eval_loader, model, optimizer, scheduler, criterion_train, criterion_eval, 50, (df_X_train_eval_transform.values, df_y_train_eval.values), 'mmoe_condition_6_loss_pp_cb')\n",
    "# train_loss(train_loader, eval_loader, model, optimizer, scheduler, criterion_train, criterion_eval, 50, (df_X_train_eval_transform.values, df_y_train_eval.values), 'mmoe_condition_6_loss_pp_cb_0')\n",
    "# train_loss(train_loader, eval_loader, model, optimizer, scheduler, criterion_train, criterion_eval, 50, (df_X_train_eval_transform.values, df_y_train_eval.values), 'mmoe_condition_6_loss_pp_cb_0_filter')\n",
    "train_loss(train_loader, eval_loader, model, optimizer, scheduler, criterion_train, criterion_eval, 50, (df_X_train_eval_transform.values, df_y_train_eval.values), 'mmoe_condition_6_loss_pp_cb_feats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bde718b-8b4c-4dec-b9eb-a7a78421d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, criterion, data_eval):\n",
    "    model.eval()\n",
    "    \n",
    "    y_true = data_eval[1]\n",
    "    num_class = y_true.shape[1]\n",
    "    \n",
    "    eval_loss = 0\n",
    "    list_eval_loss = [0] * num_class\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(test_loader):\n",
    "            x, y = x.to(device).to(torch.float32), y.to(device).to(torch.float32)\n",
    "            output = model(x)\n",
    "            list_eval_loss = [x+criterion[j](output[:, j], y[:, j]).item() for j, x in enumerate(list_eval_loss)]\n",
    "            eval_loss = sum(list_eval_loss)\n",
    "            \n",
    "            output1 = torch.sigmoid(output)\n",
    "            if i == 0:\n",
    "                y_pred = output1.cpu().numpy()\n",
    "            else:\n",
    "                y_pred = np.concatenate((y_pred, output1.cpu().numpy()), axis=0)\n",
    "    \n",
    "    list_eval_loss = [x/len(test_loader) for x in list_eval_loss]\n",
    "    eval_loss /= len(test_loader)\n",
    "    \n",
    "    eval_auc = [util.auc(y_true[:, i], y_pred[:, i]) for i in range(num_class)]\n",
    "    str_auc = ', '.join(['AUC{}: {:.6f}'.format(i, eval_auc[i]) for i in range(num_class)])\n",
    "    str_loss = 'Test set: Average loss: {:.6f}, '.format(eval_loss) + ', '.join(['Average loss{}: {:.6f}'.format(j, x) for j, x in enumerate(list_eval_loss)])\n",
    "    \n",
    "    print('{}, {}'.format(str_loss, str_auc))\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def test_loss(test_loader, model, criterion, data_eval):\n",
    "    model.eval()\n",
    "    \n",
    "    y_true = data_eval[1]\n",
    "    num_class = y_true.shape[1]\n",
    "    \n",
    "    eval_loss = 0\n",
    "    list_eval_loss = [0] * num_class\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (x, y, w1, w2, w3) in enumerate(test_loader):\n",
    "            x, y = x.to(device).to(torch.float32), y.to(device).to(torch.float32)\n",
    "            w1, w2, w3 = w1.to(device).to(torch.float32), w2.to(device).to(torch.float32), w3.to(device).to(torch.float32)\n",
    "            output = model(x)\n",
    "            # list_eval_loss = [x+criterion[j](output[:, j], y[:, j], w1).item() for j, x in enumerate(list_eval_loss[:2])] + \\\n",
    "            #     [list_eval_loss[2]+criterion[2](output[:, 2], y[:, 2], w2).item()] + \\\n",
    "            #     [x+criterion[j](output[:, j], y[:, j], w3).item() for j, x in enumerate(list_eval_loss[3:])]\n",
    "            list_eval_loss = [x+criterion[j](output[:, j], y[:, j]).item() for j, x in enumerate(list_eval_loss)]\n",
    "            eval_loss = sum(list_eval_loss)\n",
    "            \n",
    "            output1 = torch.sigmoid(output)\n",
    "            if i == 0:\n",
    "                y_pred = output1.cpu().numpy()\n",
    "            else:\n",
    "                y_pred = np.concatenate((y_pred, output1.cpu().numpy()), axis=0)\n",
    "    \n",
    "    list_eval_loss = [x/len(test_loader) for x in list_eval_loss]\n",
    "    eval_loss /= len(test_loader)\n",
    "    \n",
    "    eval_auc = [util.auc(y_true[:, i], y_pred[:, i]) for i in range(num_class)]\n",
    "    str_auc = ', '.join(['AUC{}: {:.6f}'.format(i, eval_auc[i]) for i in range(num_class)])\n",
    "    \n",
    "    # 长表\n",
    "    # eval_auc = [util.auc(y_true[:, i], y_pred[:, i]) for i in [0, 1, 3, 4]]\n",
    "    # str_auc = ', '.join(['AUC{}: {:.6f}'.format(i, eval_auc[i]) for i in range(4)])\n",
    "    \n",
    "    str_loss = 'Test set: Average loss: {:.6f}, '.format(eval_loss) + ', '.join(['Average loss{}: {:.6f}'.format(j, x) for j, x in enumerate(list_eval_loss)])\n",
    "    \n",
    "    print('{}, {}'.format(str_loss, str_auc))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b24df-6a22-4ec4-b728-35b4bdac3381",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "util.seed_everything(2023)\n",
    "\n",
    "config = {\n",
    "    'Model': {\n",
    "        'num_experts': 7, \n",
    "        'expert_hidden_units': [512, 256, 128], \n",
    "        'units': 64, \n",
    "        'num_tasks': 5, \n",
    "        'tower_hidden_units': [64, 32, 16], \n",
    "        'dropout': 0.5, \n",
    "        'use_bn': False\n",
    "    }\n",
    "}\n",
    "\n",
    "# feats_columns = utils_.load_pickle('../data/exp2suc/loss_pp_cb/feats_columns.pickle')\n",
    "feats_columns = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/feats_columns.pickle')\n",
    "\n",
    "model_rebuild = MMOE(config, feats_columns).to(device)\n",
    "\n",
    "# model_rebuild.load_state_dict(torch.load('save/mmoe_condition_6_loss_pp_cb.pth'))\n",
    "# model_rebuild.load_state_dict(torch.load('save/mmoe_condition_6_loss_pp_cb_0.pth'))\n",
    "# model_rebuild.load_state_dict(torch.load('save/mmoe_condition_6_loss_pp_cb_0_filter.pth'))\n",
    "model_rebuild.load_state_dict(torch.load('save/mmoe_condition_6_loss_pp_cb_feats.pth'))\n",
    "\n",
    "model_rebuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8ddcf-2d42-4a09-8654-2006b98e3aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_eval = utils_.load_pickle('../data/exp2suc/loss_pp_cb/df_X_pi_train_eval_transform_20230716_20231001.pickle')\n",
    "# y_eval = utils_.load_pickle('../data/exp2suc/loss_pp_cb/df_y_train_eval_20230716_20231001.pickle')\n",
    "\n",
    "X_eval = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/df_X_pi_train_eval_transform_20230716_20231001.pickle')\n",
    "y_eval = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/df_y_train_eval_20230716_20231001.pickle')\n",
    "\n",
    "print(X_eval.shape)\n",
    "print(y_eval.shape)\n",
    "\n",
    "# 权重\n",
    "# 降低\n",
    "w_pre_link_eval = X_eval[['item_id_4', 'item_id_5']].max(axis=1)\n",
    "w_pre_link_eval = w_pre_link_eval.apply(lambda x: 5 if x == 0 else 1)\n",
    "print(w_pre_link_eval.shape)\n",
    "\n",
    "w_gf_pp_eval = X_eval[['item_id_0', 'table_type_1']].sum(axis=1)\n",
    "w_gf_pp_eval = w_gf_pp_eval.apply(lambda x: 10 if x == 2 else 1)\n",
    "print(w_gf_pp_eval.shape)\n",
    "\n",
    "w_after_link_eval= X_eval[['item_id_0', 'item_id_4', 'item_id_5', 'table_type_1']].\\\n",
    "    apply(lambda x: 1 if x['item_id_0']==1 and x['table_type_1']==1 \n",
    "                      else 2 if x['item_id_4']==1 or x['item_id_5']==1 \n",
    "                             else 10, \n",
    "          axis=1)\n",
    "print(w_after_link_eval.shape)\n",
    "\n",
    "# 置0\n",
    "# w_pre_link_eval = X_eval[['item_id_4', 'item_id_5']].max(axis=1)\n",
    "# w_pre_link_eval = w_pre_link_eval.apply(lambda x: 5 if x == 0 else 1)\n",
    "# print(w_pre_link_eval.shape)\n",
    "\n",
    "# w_gf_pp_eval = X_eval[['item_id_0', 'table_type_1']].sum(axis=1)\n",
    "# w_gf_pp_eval = w_gf_pp_eval.apply(lambda x: 1 if x == 2 else 0)\n",
    "# print(w_gf_pp_eval.shape)\n",
    "\n",
    "# w_after_link_eval= X_eval[['item_id_0', 'item_id_4', 'item_id_5', 'table_type_1']].\\\n",
    "#     apply(lambda x: 0 if x['item_id_0']==1 and x['table_type_1']==1 \n",
    "#                       else 1 if x['item_id_4']==1 or x['item_id_5']==1 \n",
    "#                              else 5, \n",
    "#           axis=1)\n",
    "# print(w_after_link_eval.shape)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    DatasetLoader_www(X_eval.values, y_eval.values, \n",
    "                      w_pre_link_eval.values, w_gf_pp_eval.values, w_after_link_eval.values), \n",
    "    1024, shuffle=False, num_workers=8)\n",
    "\n",
    "criterion = (torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device))\n",
    "\n",
    "y_pred = test_loss(test_loader, model_rebuild, criterion, (X_eval.values, y_eval.values))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "464225b7-3e1a-4be2-9710-7f73066cb167",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7dc78a-9871-40fd-a036-bf62fe3d7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.concat([y_eval.reset_index(drop=True), pd.DataFrame(data=y_pred, columns=['pred_'+x for x in y_eval.columns])], axis=1)\n",
    "print(df_y.shape)\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75337409-6fba-4051-a60e-f3c1e7e0b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_recall(df_y, y_true, y_pred, threshold=0.3):\n",
    "    df_y_sort = df_y.copy()\n",
    "    df_y_sort.sort_values(by=y_pred, ascending=False, inplace=True)\n",
    "    df_y_sort.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df_y_sort['label_recall'] = 0\n",
    "    df_y_sort.loc[:int(df_y_sort.shape[0]*threshold), 'label_recall'] = 1\n",
    "    \n",
    "    dict_cr = classification_report(df_y_sort[y_true], df_y_sort['label_recall'], output_dict=True)\n",
    "    \n",
    "    return dict_cr['1.0']['recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c521f-0164-497e-b34f-f24f3c2c6d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with tqdm(y_eval.columns) as t:\n",
    "        for x in t:\n",
    "            print('{}: {}'.format(x, cal_recall(df_y[[x, 'pred_'+x]], x, 'pred_'+x, threshold=0.2)))\n",
    "except KeyboardInterrupt:\n",
    "    t.close()\n",
    "    raise\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e49c83fc-96b8-42f1-9775-7e21bd86f45f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8441675-330d-4c98-bf7a-30499abd43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_id_train_eval = utils_.load_pickle('../data/exp2suc/loss_pp_cb/df_id_train_eval_20230716_20231001.pickle')\n",
    "df_id_train_eval = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/df_id_train_eval_20230716_20231001.pickle')\n",
    "\n",
    "print(df_id_train_eval.shape)\n",
    "df_id_train_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aa5585-37cb-419c-b603-c818b0c150c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_train_eval_ = df_id_train_eval.reset_index(drop=True)\n",
    "df_id_train_eval_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda7c092-a680-48ea-8daf-a9cd704ce38f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "recall_p = 20\n",
    "list_tuple_item_table = [\n",
    "    (0, 1), # aa短表\n",
    "    (0, 2), # aa长表\n",
    "    (1, 2), # bb长表\n",
    "    (2, 2), # cc长表\n",
    "    (3, 2), # dd长表\n",
    "    (4, 2), # ee长表\n",
    "    (5, 2)  # ff长表\n",
    "]\n",
    "\n",
    "try:\n",
    "    with tqdm(list_tuple_item_table) as t:\n",
    "        for item_id, table_type in t:\n",
    "            print('item_id:{bi}, table_type:{tt}'.format(bi=item_id, tt=table_type))\n",
    "            \n",
    "            index_item_table = df_id_train_eval_[\n",
    "                (df_id_train_eval_['item_id']==item_id)\n",
    "                &(df_id_train_eval_['table_type']==table_type)].index\n",
    "            df_y_item_table = df_y.loc[index_item_table, :]\n",
    "            print(df_y_item_table.shape[0])\n",
    "            \n",
    "            list_label = y_eval.columns\n",
    "            if table_type == 1:\n",
    "                list_label = [x for x in list_label if x not in ['label_pass', 'label_pass_1']]\n",
    "            else:\n",
    "                list_label = [x for x in list_label if x not in ['label_pre_pass']]\n",
    "                \n",
    "            for x in list_label:\n",
    "                if df_y_item_table[df_y_item_table[x]==1].shape[0] == 0:\n",
    "                    continue\n",
    "                print('{l}, AUC:{ras}, Recall@{p}%:{cr}'.format(\n",
    "                    l=x, \n",
    "                    ras=roc_auc_score(df_y_item_table[x], df_y_item_table['pred_'+x]), \n",
    "                    p=recall_p, \n",
    "                    cr=cal_recall(df_y_item_table, x, 'pred_'+x, threshold=recall_p*0.01)))\n",
    "except:\n",
    "    t.close()\n",
    "    raise\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3412c77-c4c1-4b44-9565-6d968ef2b5ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14b2fe39-1ee1-41fb-b6e3-966fd44f2376",
   "metadata": {},
   "source": [
    "* 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4a534-bf51-404f-934a-b49b0e975a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusion = pd.read_csv('../data/exp2suc/sample_label_feature_fusion_test_20230716_20231001.txt', sep='\\t', encoding='utf-8')\n",
    "df_asp1 = pd.read_csv('../data/exp2suc/sample_label_feature_aspiration_part1_test_20230716_20231001.txt', sep='\\t', encoding='utf-8')\n",
    "df_asp2 = pd.read_csv('../data/exp2suc/sample_label_feature_aspiration_part2_test_20230716_20231001.txt', sep='\\t', encoding='utf-8')\n",
    "\n",
    "print(df_fusion.shape)\n",
    "print(df_asp1.shape)\n",
    "print(df_asp2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810c2f6b-a45b-49e0-a24a-dd9b87f7939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_id_dt_item_y = ['uid', 'obs_dt', 'dt', 'item', 'table_type', 'label_apply', 'label_submit', 'label_pre_pass', 'label_pass', 'label_pass_1']\n",
    "\n",
    "list_feats_x_fusion = [x for x in \n",
    "                       utils_.load_pickle('../data/exp2suc/list_feats/list_feats_x_fusion_pi_20230716_20231001.pickle') \n",
    "                       if x not in \n",
    "                       ['pqg_last_7_day_didipay_use_ticket_discount_amount']\n",
    "                      ]\n",
    "list_feats_x_asp1 = [x for x in \n",
    "                     utils_.load_pickle('../data/exp2suc/list_feats/list_feats_x_asp1_pi_20230716_20231001.pickle') \n",
    "                     if x not in \n",
    "                     []\n",
    "                    ]\n",
    "list_feats_x_asp2 = [x for x in \n",
    "                     utils_.load_pickle('../data/exp2suc/list_feats/list_feats_x_asp2_pi_20230716_20231001.pickle') \n",
    "                     if x not in \n",
    "                     []\n",
    "                    ]\n",
    "\n",
    "print(len(list_feats_x_fusion))\n",
    "print(len(list_feats_x_asp1))\n",
    "print(len(list_feats_x_asp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71769655-ec36-400d-9310-ca18fe5abfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_fusion[list_feats_id_dt_item_y+list_feats_x_fusion].\\\n",
    "    merge(df_asp1[list_feats_id_dt_item_y+list_feats_x_asp1]).\\\n",
    "    merge(df_asp2[list_feats_id_dt_item_y+list_feats_x_asp2])\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2081005-e0ba-4c7f-8819-da1d26ed08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_des = utils_.df_des(df)\n",
    "df_des.to_csv('../data/exp2suc/df_des_pi_test_20230716_20231001.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7022f9-cbf4-40ce-8e16-67f0fa9c22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_item = {\n",
    "    'aaa': 0, \n",
    "    'bbb': 1, \n",
    "    'ccc': 2, \n",
    "    'ddd': 3, \n",
    "    'eee': 4, \n",
    "    'fff': 5\n",
    "}\n",
    "\n",
    "df['item_id'] = df['item']\n",
    "df['item_id'].replace(dict_item, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab78720-7a10-4e55-b0f6-619b50a7790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['item', 'item_id', 'table_type', 'uid']].groupby(['item', 'item_id', 'table_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34fb8f-9ae9-4dd9-8ea4-3af2c30ca3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 物料\\表类型特征处理\n",
    "# one hot encoding\n",
    "list_feats_ohe = ['item_id', 'table_type']\n",
    "list_df_ohe = []\n",
    "try:\n",
    "    with tqdm(list_feats_ohe) as t:\n",
    "        for feat in t:\n",
    "            df_ohe_feat = utils_.one_hot_encoder(df, feat)\n",
    "            list_df_ohe.append(df_ohe_feat)\n",
    "except KeyboardInterrupt:\n",
    "    t.close()\n",
    "    raise\n",
    "t.close()\n",
    "\n",
    "df_ohe_part = pd.concat(list_df_ohe, axis=1)\n",
    "print(df_ohe_part.shape)\n",
    "df_ohe_part.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f58fdc-f86b-4d4e-8834-fc4dac73d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = pd.concat([df, df_ohe_part], axis=1)\n",
    "print(df_ohe.shape)\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa88638-99d9-4e58-82fe-f0b6502eb8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_.save_pickle(df_ohe, '../data/exp2suc/df_pi_ohe_test_20230716_20231001.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0fe0e1-efc1-4bc4-9596-43d1ccfdd12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = utils_.load_pickle('../data/exp2suc/df_pi_ohe_test_20230716_20231001.pickle')\n",
    "print(df_ohe.shape)\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289b25d0-2541-4095-af96-b6306660f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition_feats_item = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_condition_feats_item.pickle')\n",
    "# condition_feats_table = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_condition_feats_table.pickle')\n",
    "# sparse_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_sparse_feats.pickle')\n",
    "# dense_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_dense_feats.pickle')\n",
    "\n",
    "condition_feats_item = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_condition_feats_item.pickle')\n",
    "condition_feats_table = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_condition_feats_table.pickle')\n",
    "sparse_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_sparse_feats.pickle')\n",
    "dense_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_dense_feats.pickle')\n",
    "\n",
    "print(len(condition_feats_item))\n",
    "print(len(condition_feats_table))\n",
    "print(len(sparse_feats))\n",
    "print(len(dense_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968e8bad-966b-4850-849b-58d48c12246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连续\n",
    "# ss = joblib.load('../data/exp2suc/loss_pp_cb/ss.pickle')\n",
    "ss = joblib.load('../data/exp2suc/loss_pp_cb_feats/ss.pickle')\n",
    "\n",
    "X_dense_ss = ss.transform(df_ohe[dense_feats])\n",
    "print(X_dense_ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ccb3e1-8d9b-4551-b073-42ce34ec1aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_dense = pd.DataFrame(X_dense_ss, columns=dense_feats)\n",
    "print(df_X_dense.shape)\n",
    "df_X_dense.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8aaca9-d106-4446-9980-50205a9c50e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 离散\n",
    "# dict_lbe = joblib.load('../data/exp2suc/loss_pp_cb/dict_lbe.pickle')\n",
    "dict_lbe = joblib.load('../data/exp2suc/loss_pp_cb_feats/dict_lbe.pickle')\n",
    "\n",
    "for x in sparse_feats:\n",
    "    print(x, dict_lbe[x].classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d3ee5-4a3d-4b3d-8063-69a88fedd4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_X_sparse = []\n",
    "\n",
    "try:\n",
    "    with tqdm(sparse_feats) as t:\n",
    "        for x in t:\n",
    "            list_feat_values_unseen = list(set(df_ohe[x].unique())-set(dict_lbe[x].classes_))\n",
    "            if len(list_feat_values_unseen) > 0:\n",
    "                print(x)\n",
    "                df_ohe[x].replace(list_feat_values_unseen, -1, inplace=True)\n",
    "            df_X_sparse_each = pd.DataFrame(dict_lbe[x].transform(df_ohe[x]), columns=[x])\n",
    "            list_X_sparse.append(df_X_sparse_each)\n",
    "except KeyboardInterrupt:\n",
    "    t.close()\n",
    "    raise\n",
    "t.close()\n",
    "\n",
    "df_X_sparse = pd.concat(list_X_sparse, axis=1)\n",
    "print(df_X_sparse.shape)\n",
    "df_X_sparse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d8762-a2f8-457d-a40c-bdc4f2f27b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并\n",
    "df_X_condition_item = df_ohe[condition_feats_item]\n",
    "df_X_condition_table = df_ohe[condition_feats_table]\n",
    "df_X_transform = pd.concat([df_X_condition_item, df_X_condition_table, df_X_sparse, df_X_dense], axis=1)\n",
    "print(df_X_transform.shape)\n",
    "df_X_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24bf5ee-e4fc-4836-b3f4-024af74ec8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 权重\n",
    "# 降低\n",
    "w_pre_link_eval = df_X_transform[['item_id_4', 'item_id_5']].max(axis=1)\n",
    "w_pre_link_eval = w_pre_link_eval.apply(lambda x: 5 if x == 0 else 1)\n",
    "print(w_pre_link_eval.shape)\n",
    "\n",
    "w_gf_pp_eval = df_X_transform[['item_id_0', 'table_type_1']].sum(axis=1)\n",
    "w_gf_pp_eval = w_gf_pp_eval.apply(lambda x: 10 if x == 2 else 1)\n",
    "print(w_gf_pp_eval.shape)\n",
    "\n",
    "w_after_link_eval= df_X_transform[['item_id_0', 'item_id_4', 'item_id_5', 'table_type_1']].\\\n",
    "    apply(lambda x: 1 if x['item_id_0']==1 and x['table_type_1']==1 \n",
    "                      else 2 if x['item_id_4']==1 or x['item_id_5']==1 \n",
    "                             else 10, \n",
    "          axis=1)\n",
    "print(w_after_link_eval.shape)\n",
    "\n",
    "# 置0\n",
    "# w_pre_link_eval = df_X_transform[['item_id_4', 'item_id_5']].max(axis=1)\n",
    "# w_pre_link_eval = w_pre_link_eval.apply(lambda x: 5 if x == 0 else 1)\n",
    "# print(w_pre_link_eval.shape)\n",
    "\n",
    "# w_gf_pp_eval = df_X_transform[['item_id_0', 'table_type_1']].sum(axis=1)\n",
    "# w_gf_pp_eval = w_gf_pp_eval.apply(lambda x: 1 if x == 2 else 0)\n",
    "# print(w_gf_pp_eval.shape)\n",
    "\n",
    "# w_after_link_eval= df_X_transform[['item_id_0', 'item_id_4', 'item_id_5', 'table_type_1']].\\\n",
    "#     apply(lambda x: 0 if x['item_id_0']==1 and x['table_type_1']==1 \n",
    "#                       else 1 if x['item_id_4']==1 or x['item_id_5']==1 \n",
    "#                              else 5, \n",
    "#           axis=1)\n",
    "# print(w_after_link_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c0730-bd4b-4798-b3d5-94947610b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_ohe[['label_apply', 'label_submit', 'label_pre_pass', 'label_pass', 'label_pass_1']]\n",
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f985bf-c00d-479a-9dbd-d808de39364e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "util.seed_everything(2023)\n",
    "\n",
    "config = {\n",
    "    'Model': {\n",
    "        'num_experts': 7, \n",
    "        'expert_hidden_units': [512, 256, 128], \n",
    "        'units': 64, \n",
    "        'num_tasks': 5, \n",
    "        'tower_hidden_units': [64, 32, 16], \n",
    "        'dropout': 0.5, \n",
    "        'use_bn': False\n",
    "    }\n",
    "}\n",
    "\n",
    "# feats_columns = utils_.load_pickle('../data/exp2suc/loss_pp_cb/feats_columns.pickle')\n",
    "feats_columns = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/feats_columns.pickle')\n",
    "\n",
    "model = MMOE(config, feats_columns).to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load('save/mmoe_condition_6_loss_pp_cb.pth'))\n",
    "# model.load_state_dict(torch.load('save/mmoe_condition_6_loss_pp_cb_0.pth'))\n",
    "# model.load_state_dict(torch.load('save/mmoe_condition_6_loss_pp_cb_0_filter.pth'))\n",
    "model.load_state_dict(torch.load('save/mmoe_condition_6_loss_pp_cb_feats.pth'))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f32873-2e04-4d55-8747-0e3956f2257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    DatasetLoader_www(df_X_transform.values, y.values, \n",
    "                      w_pre_link_eval.values, w_gf_pp_eval.values, w_after_link_eval.values), \n",
    "    1024, shuffle=False, num_workers=8)\n",
    "\n",
    "criterion = (torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device))\n",
    "\n",
    "y_pred = test_loss(test_loader, model, criterion, (df_X_transform.values, y.values))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "116cd458-9db1-4ef1-bb17-b1eb80b616a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ebd11-fc66-4199-8aff-194a4a1b7517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.concat([y, pd.DataFrame(data=y_pred, columns=['pred_'+x for x in y.columns])], axis=1)\n",
    "print(df_y.shape)\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e721baef-59b7-49aa-8f66-8a0bdb7d4770",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with tqdm(y.columns) as t:\n",
    "        for x in t:\n",
    "            print('{}: {}'.format(x, cal_recall(df_y[[x, 'pred_'+x]], x, 'pred_'+x, threshold=0.2)))\n",
    "except KeyboardInterrupt:\n",
    "    t.close()\n",
    "    raise\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2a9a043-86ae-49f3-add2-692fb639ca07",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5789b-eef9-42e0-aa79-d5aaa9adb6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = df_ohe[['uid', 'obs_dt', 'dt', 'item', 'item_id', 'table_type']]\n",
    "df_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b999b9cc-840f-4e21-b28b-164f0e2a5051",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 分物料、表类型\n",
    "recall_p = 20\n",
    "list_tuple_item_table = [\n",
    "    (0, 1), # aa短表\n",
    "    (0, 2), # aa长表\n",
    "    (1, 2), # bb长表\n",
    "    (2, 2), # cc长表\n",
    "    (3, 2), # dd长表\n",
    "    (4, 2), # ee长表\n",
    "    (5, 2)  # ff长表\n",
    "]\n",
    "\n",
    "try:\n",
    "    with tqdm(list_tuple_item_table) as t:\n",
    "        for item_id, table_type in t:\n",
    "            print('item_id:{bi}, table_type:{tt}'.format(bi=item_id, tt=table_type))\n",
    "            \n",
    "            index_item_table = df_id[\n",
    "                (df_id['item_id']==item_id)\n",
    "                &(df_id['table_type']==table_type)].index\n",
    "            df_y_item_table = df_y.loc[index_item_table, :]\n",
    "            print(df_y_item_table.shape[0])\n",
    "            \n",
    "            list_label = y.columns\n",
    "            if table_type == 1:\n",
    "                list_label = [x for x in list_label if x not in ['label_pass', 'label_pass_1']]\n",
    "            else:\n",
    "                list_label = [x for x in list_label if x not in ['label_pre_pass']]\n",
    "                \n",
    "            for x in list_label:\n",
    "                if df_y_item_table[df_y_item_table[x]==1].shape[0] == 0:\n",
    "                    continue\n",
    "                print('{l}, AUC:{ras}, Recall@{p}%:{cr}'.format(\n",
    "                    l=x, \n",
    "                    ras=roc_auc_score(df_y_item_table[x], df_y_item_table['pred_'+x]), \n",
    "                    p=recall_p, \n",
    "                    cr=cal_recall(df_y_item_table, x, 'pred_'+x, threshold=recall_p*0.01)))\n",
    "except:\n",
    "    t.close()\n",
    "    raise\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b57bf4f5-afe5-4eca-96fd-25c818dded4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "161a2328-7e16-4eb5-84ac-b11458caa55e",
   "metadata": {},
   "source": [
    "* feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ddf2b-55e4-42eb-a42b-587a2162fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap\n",
    "shap_explainer = shap.DeepExplainer(model, [df_X_transform.values])\n",
    "shap_explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f6b5d-d44e-49d4-ac12-2b6d92497597",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap_explainer.shap_values([df_X_transform.values])\n",
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f3eb4b-d162-4763-b2e8-f47b39de7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, df_train_X, plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bb1c58-e3a4-4809-957a-4ad7e3dbd951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57dc65b6-d752-4d43-b3ce-c4ba9c3b510c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 模型比较，oot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5abc537-d14e-4f11-b8c9-a664a4be2e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_fusion = pd.read_csv('../data/exp2suc/sample_label_feature_fusion_pi_20231008.txt', sep='\\t', encoding='utf-8')\n",
    "df_asp1 = pd.read_csv('../data/exp2suc/sample_label_feature_aspiration_part1_pi_20231008.txt', sep='\\t', encoding='utf-8')\n",
    "df_asp2 = pd.read_csv('../data/exp2suc/sample_label_feature_aspiration_part2_pi_20231008.txt', sep='\\t', encoding='utf-8')\n",
    "\n",
    "print(df_fusion.shape)\n",
    "print(df_asp1.shape)\n",
    "print(df_asp2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3542fd-86f2-494b-9e15-763174a34db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_id_dt_item_y = ['uid', 'obs_dt', 'dt', 'item', 'table_type', 'label_apply', 'label_submit', 'label_pre_pass', 'label_pass', 'label_pass_1']\n",
    "\n",
    "list_feats_x_fusion = [x for x in \n",
    "                       utils_.load_pickle('../data/exp2suc/list_feats/list_feats_x_fusion_pi_20230716_20231001.pickle') \n",
    "                       if x not in \n",
    "                       ['xxx']\n",
    "                      ]\n",
    "list_feats_x_asp1 = [x for x in \n",
    "                     utils_.load_pickle('../data/exp2suc/list_feats/list_feats_x_asp1_pi_20230716_20231001.pickle') \n",
    "                     if x not in \n",
    "                     []\n",
    "                    ]\n",
    "list_feats_x_asp2 = [x for x in \n",
    "                     utils_.load_pickle('../data/exp2suc/list_feats/list_feats_x_asp2_pi_20230716_20231001.pickle') \n",
    "                     if x not in \n",
    "                     []\n",
    "                    ]\n",
    "\n",
    "print(len(list_feats_x_fusion))\n",
    "print(len(list_feats_x_asp1))\n",
    "print(len(list_feats_x_asp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0f4485-4793-4910-a1a1-713b07f3898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_fusion[list_feats_id_dt_item_y+list_feats_x_fusion].\\\n",
    "    merge(df_asp1[list_feats_id_dt_item_y+list_feats_x_asp1]).\\\n",
    "    merge(df_asp2[list_feats_id_dt_item_y+list_feats_x_asp2])\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e8ac8-b678-4061-8877-3f35a53d9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_des = utils_.df_des(df)\n",
    "df_des.to_csv('../data/exp2suc/df_des_pi_20231008.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "97874e77-aa76-4e30-8736-2f339ce15a2d",
   "metadata": {},
   "source": [
    "特征缺失\n",
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad225af2-6e98-400f-a3ac-663017c78e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_item = {\n",
    "    'aaa': 0, \n",
    "    'bbb': 1, \n",
    "    'ccc': 2, \n",
    "    'ddd': 3, \n",
    "    'eee': 4, \n",
    "    'fff': 5\n",
    "}\n",
    "\n",
    "df['item_id'] = df['item']\n",
    "df['item_id'].replace(dict_item, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f6949d-3163-4867-9e94-aca350189ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['item', 'item_id', 'table_type', 'uid']].groupby(['item', 'item_id', 'table_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b409c167-0f9e-4896-8f95-a85875ebce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 物料\\表类型特征处理\n",
    "# one hot encoding\n",
    "list_feats_ohe = ['item_id', 'table_type']\n",
    "list_df_ohe = []\n",
    "try:\n",
    "    with tqdm(list_feats_ohe) as t:\n",
    "        for feat in t:\n",
    "            df_ohe_feat = utils_.one_hot_encoder(df, feat)\n",
    "            list_df_ohe.append(df_ohe_feat)\n",
    "except KeyboardInterrupt:\n",
    "    t.close()\n",
    "    raise\n",
    "t.close()\n",
    "\n",
    "df_ohe_part = pd.concat(list_df_ohe, axis=1)\n",
    "print(df_ohe_part.shape)\n",
    "df_ohe_part.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c73dda-5c85-4869-944c-003393adece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = pd.concat([df, df_ohe_part], axis=1)\n",
    "print(df_ohe.shape)\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3049b-159f-4a94-aa6c-da924194ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_.save_pickle(df_ohe, '../data/exp2suc/df_pi_ohe_20231008.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b7aec-d6d3-42c3-8ce6-8524173fab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = utils_.load_pickle('../data/exp2suc/df_pi_ohe_20231008.pickle')\n",
    "print(df_ohe.shape)\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02537c6-267a-40a8-a6c6-f869822f347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 长表，4物料\n",
    "df_ohe = df_ohe[\n",
    "    (df_ohe['table_type']==2)\n",
    "    # &(df_ohe['item'].isin(['aaa', 'bbb', 'ccc','ddd']))\n",
    "]\n",
    "df_ohe.reset_index(drop=True, inplace=True)\n",
    "print(df_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d037fe-ceb2-4b23-8044-6cb081446289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition_feats_item = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_condition_feats_item.pickle')\n",
    "# condition_feats_table = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_condition_feats_table.pickle')\n",
    "# sparse_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_sparse_feats.pickle')\n",
    "# dense_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb/list_dense_feats.pickle')\n",
    "\n",
    "condition_feats_item = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_condition_feats_item.pickle')\n",
    "condition_feats_table = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_condition_feats_table.pickle')\n",
    "sparse_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_sparse_feats.pickle')\n",
    "dense_feats = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/list_dense_feats.pickle')\n",
    "\n",
    "print(len(condition_feats_item))\n",
    "print(len(condition_feats_table))\n",
    "print(len(sparse_feats))\n",
    "print(len(dense_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd56958-5274-451d-b19a-a4efe7144dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连续\n",
    "# ss = joblib.load('../data/exp2suc/loss_pp_cb/ss.pickle')\n",
    "ss = joblib.load('../data/exp2suc/loss_pp_cb_feats/ss.pickle')\n",
    "\n",
    "X_dense_ss = ss.transform(df_ohe[dense_feats])\n",
    "print(X_dense_ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93565827-1ae5-4166-8163-b6943cc0ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_dense = pd.DataFrame(X_dense_ss, columns=dense_feats)\n",
    "print(df_X_dense.shape)\n",
    "df_X_dense.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2100ecc-f6dc-4243-a16c-9a6f18d28e66",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 离散\n",
    "# dict_lbe = joblib.load('../data/exp2suc/loss_pp_cb/dict_lbe.pickle')\n",
    "dict_lbe = joblib.load('../data/exp2suc/loss_pp_cb_feats/dict_lbe.pickle')\n",
    "\n",
    "for x in sparse_feats:\n",
    "    print(x, dict_lbe[x].classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81928083-43d8-4a44-acb5-e82d48e278bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_X_sparse = []\n",
    "\n",
    "try:\n",
    "    with tqdm(sparse_feats) as t:\n",
    "        for x in t:\n",
    "            list_feat_values_unseen = list(set(df_ohe[x].unique())-set(dict_lbe[x].classes_))\n",
    "            if len(list_feat_values_unseen) > 0:\n",
    "                print(x)\n",
    "                df_ohe[x].replace(list_feat_values_unseen, -1, inplace=True)\n",
    "            df_X_sparse_each = pd.DataFrame(dict_lbe[x].transform(df_ohe[x]), columns=[x])\n",
    "            list_X_sparse.append(df_X_sparse_each)\n",
    "except KeyboardInterrupt:\n",
    "    t.close()\n",
    "    raise\n",
    "t.close()\n",
    "\n",
    "df_X_sparse = pd.concat(list_X_sparse, axis=1)\n",
    "print(df_X_sparse.shape)\n",
    "df_X_sparse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb65a52-6311-419f-9432-0e1be7e99a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并\n",
    "df_X_condition_item = df_ohe[condition_feats_item]\n",
    "df_X_condition_table = df_ohe[condition_feats_table]\n",
    "df_X_transform = pd.concat([df_X_condition_item, df_X_condition_table, df_X_sparse, df_X_dense], axis=1)\n",
    "print(df_X_transform.shape)\n",
    "df_X_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d84b1a5-8d29-4d87-8aeb-4dd1e0f46698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 权重\n",
    "# 降低\n",
    "w_pre_link_eval = df_X_transform[['item_id_4', 'item_id_5']].max(axis=1)\n",
    "w_pre_link_eval = w_pre_link_eval.apply(lambda x: 5 if x == 0 else 1)\n",
    "print(w_pre_link_eval.shape)\n",
    "\n",
    "w_gf_pp_eval = df_X_transform[['item_id_0', 'table_type_1']].sum(axis=1)\n",
    "w_gf_pp_eval = w_gf_pp_eval.apply(lambda x: 10 if x == 2 else 1)\n",
    "print(w_gf_pp_eval.shape)\n",
    "\n",
    "w_after_link_eval= df_X_transform[['item_id_0', 'item_id_4', 'item_id_5', 'table_type_1']].\\\n",
    "    apply(lambda x: 1 if x['item_id_0']==1 and x['table_type_1']==1 \n",
    "                      else 2 if x['item_id_4']==1 or x['item_id_5']==1 \n",
    "                             else 10, \n",
    "          axis=1)\n",
    "print(w_after_link_eval.shape)\n",
    "\n",
    "# 置0\n",
    "# w_pre_link_eval = df_X_transform[['item_id_4', 'item_id_5']].max(axis=1)\n",
    "# w_pre_link_eval = w_pre_link_eval.apply(lambda x: 5 if x == 0 else 1)\n",
    "# print(w_pre_link_eval.shape)\n",
    "\n",
    "# w_gf_pp_eval = df_X_transform[['item_id_0', 'table_type_1']].sum(axis=1)\n",
    "# w_gf_pp_eval = w_gf_pp_eval.apply(lambda x: 1 if x == 2 else 0)\n",
    "# print(w_gf_pp_eval.shape)\n",
    "\n",
    "# w_after_link_eval= df_X_transform[['item_id_0', 'item_id_4', 'item_id_5', 'table_type_1']].\\\n",
    "#     apply(lambda x: 0 if x['item_id_0']==1 and x['table_type_1']==1 \n",
    "#                       else 1 if x['item_id_4']==1 or x['item_id_5']==1 \n",
    "#                              else 5, \n",
    "#           axis=1)\n",
    "# print(w_after_link_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0907a0-31bd-4723-aff1-aec567d62a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_ohe[['label_apply', 'label_submit', 'label_pre_pass', 'label_pass', 'label_pass_1']]\n",
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6095354f-3843-43b9-80a5-5db70b71e21c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "util.seed_everything(2023)\n",
    "\n",
    "config = {\n",
    "    'Model': {\n",
    "        'num_experts': 7, \n",
    "        'expert_hidden_units': [512, 256, 128], \n",
    "        'units': 64, \n",
    "        'num_tasks': 5, \n",
    "        'tower_hidden_units': [64, 32, 16], \n",
    "        'dropout': 0.5, \n",
    "        'use_bn': False\n",
    "    }\n",
    "}\n",
    "\n",
    "# feats_columns = utils_.load_pickle('../data/exp2suc/loss_pp_cb/feats_columns.pickle')\n",
    "feats_columns = utils_.load_pickle('../data/exp2suc/loss_pp_cb_feats/feats_columns.pickle')\n",
    "\n",
    "model = MMOE(config, feats_columns).to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load('save/mmoe_condition_6_loss_pp_cb.pth'))\n",
    "# model.load_state_dict(torch.load('save/mmoe_condition_6_loss_pp_cb_0.pth'))\n",
    "# model.load_state_dict(torch.load('save/mmoe_condition_6_loss_pp_cb_0_filter.pth'))\n",
    "model.load_state_dict(torch.load('save/mmoe_condition_6_loss_pp_cb_feats.pth'))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892533d7-9581-4b95-b2c7-a01e933a7ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    DatasetLoader_www(\n",
    "        df_X_transform.values, y.values, \n",
    "        w_pre_link_eval.values, w_gf_pp_eval.values, w_after_link_eval.values), \n",
    "    1024, shuffle=False, num_workers=8)\n",
    "\n",
    "criterion = (torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device), torch.nn.BCEWithLogitsLoss().to(device))\n",
    "\n",
    "y_pred = test_loss(test_loader, model, criterion, (df_X_transform.values, y.values))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11e1e2a4-0e16-4ac6-af5c-b29951d8c82b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359c602d-3970-4943-8bc7-32f9d1262ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.concat([y, pd.DataFrame(data=y_pred, columns=['pred_'+x for x in y.columns])], axis=1)\n",
    "print(df_y.shape)\n",
    "df_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03252862-feea-4a34-ba92-2dd40cc6251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with tqdm(y.columns) as t:\n",
    "        for x in t:\n",
    "            print('{}: {}'.format(x, cal_recall(df_y[[x, 'pred_'+x]], x, 'pred_'+x, threshold=0.2)))\n",
    "except KeyboardInterrupt:\n",
    "    t.close()\n",
    "    raise\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45ec94-5bc6-4876-984c-a4e81415d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_recall(df_y[['label_pass_1', 'pred_label_pass_1']], 'label_pass_1', 'pred_label_pass_1', threshold=0.2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41214527-d2f4-4c99-8fdd-a63b4a906440",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e07e50-b736-4862-b38e-8df857477857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = df_ohe[['uid', 'obs_dt', 'dt', 'item', 'item_id', 'table_type']]\n",
    "df_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a706ca-ee05-4a78-acef-7d136480ae0f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 分物料、表类型\n",
    "recall_p = 20\n",
    "list_tuple_item_table = [\n",
    "    (0, 1), # aa短表\n",
    "    (0, 2), # aa长表\n",
    "    (1, 2), # bb长表\n",
    "    (2, 2), # cc长表\n",
    "    (3, 2), # dd长表\n",
    "    (4, 2), # ee长表\n",
    "    (5, 2)  # ff长表\n",
    "]\n",
    "\n",
    "try:\n",
    "    with tqdm(list_tuple_item_table) as t:\n",
    "        for item_id, table_type in t:\n",
    "            print('item_id:{bi}, table_type:{tt}'.format(bi=item_id, tt=table_type))\n",
    "            \n",
    "            index_item_table = df_id[\n",
    "                (df_id['item_id']==item_id)\n",
    "                &(df_id['table_type']==table_type)].index\n",
    "            df_y_item_table = df_y.loc[index_item_table, :]\n",
    "            print(df_y_item_table.shape[0])\n",
    "            \n",
    "            list_label = y.columns\n",
    "            if table_type == 1:\n",
    "                list_label = [x for x in list_label if x not in ['label_pass', 'label_pass_1']]\n",
    "            else:\n",
    "                list_label = [x for x in list_label if x not in ['label_pre_pass']]\n",
    "                \n",
    "            for x in list_label:\n",
    "                if df_y_item_table[df_y_item_table[x]==1].shape[0] == 0:\n",
    "                    continue\n",
    "                print('{l}, AUC:{ras}, Recall@{p}%:{cr}'.format(\n",
    "                    l=x, \n",
    "                    ras=roc_auc_score(df_y_item_table[x], df_y_item_table['pred_'+x]), \n",
    "                    p=recall_p, \n",
    "                    cr=cal_recall(df_y_item_table, x, 'pred_'+x, threshold=recall_p*0.01)))\n",
    "except:\n",
    "    t.close()\n",
    "    raise\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20b42f7a-8e34-4a91-9e03-136848ce7c59",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepctr)",
   "language": "python",
   "name": "deepctr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
