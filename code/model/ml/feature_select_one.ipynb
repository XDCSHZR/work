{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature select one\n",
    "## 分期支付"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_178361/956590377.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jarretthan/lib/python3.7/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpolynomial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mctypeslib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jarretthan/lib/python3.7/site-packages/numpy/polynomial/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpolynomial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolynomial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mchebyshev\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChebyshev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlegendre\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLegendre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhermite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHermite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhermite_e\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHermiteE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jarretthan/lib/python3.7/site-packages/numpy/polynomial/legendre.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1618\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLegendre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mABCPolyBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1619\u001b[0m     \"\"\"A Legendre series class.\n\u001b[1;32m   1620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jarretthan/lib/python3.7/abc.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(mcls, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0m_abc_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import re\n",
    "import copy\n",
    "import lightgbm as lgb\n",
    "\n",
    "import utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('max_row', 500)\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas(desc='pandas bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/sample_label_feature_fusion_obs_dt_20231217_20240204.txt', sep='\\t', encoding='utf-8')\n",
    "# df = pd.read_csv('data/sample_label_feature_asp1_obs_dt_20231217_20240204.txt', sep='\\t', encoding='utf-8')\n",
    "# df = pd.read_csv('data/sample_label_feature_asp2_obs_dt_20231217_20240204.txt', sep='\\t', encoding='utf-8')\n",
    "# df = pd.read_csv('data/sample_label_feature_bank_card_debit_obs_dt_20231217_20240204.txt', sep='\\t', encoding='utf-8')\n",
    "\n",
    "# df = pd.read_csv('data/sample_label_feature_fusion_instal_obs_dt_20231217_20240303.txt', sep='\\t', encoding='utf-8')\n",
    "# df = pd.read_csv('data/sample_label_feature_asp1_instal_obs_dt_20231217_20240303.txt', sep='\\t', encoding='utf-8')\n",
    "# df = pd.read_csv('data/sample_label_feature_asp2_instal_obs_dt_20231217_20240303.txt', sep='\\t', encoding='utf-8')\n",
    "# df = pd.read_csv('data/sample_label_feature_dbc_instal_obs_dt_20231217_20240303.txt', sep='\\t', encoding='utf-8')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in df.columns if x.endswith('.1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['pay_type']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['obs_dt', 'uid']].groupby(by=['obs_dt']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['pay_type', 'default_chose_type', 'label', 'uid']].groupby(by=['pay_type', 'default_chose_type', 'label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['pay_type']==1]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['obs_dt'] = pd.to_datetime(df['obs_dt'])\n",
    "df['dt'] = pd.to_datetime(df['dt'])\n",
    "\n",
    "# utils.save_pickle(df, 'data/df_sample_label_feature_fusion_one_obs_dt_20231217_20240204.pickle')\n",
    "# utils.save_pickle(df, 'data/df_sample_label_feature_asp1_one_obs_dt_20231217_20240204.pickle')\n",
    "# utils.save_pickle(df, 'data/df_sample_label_feature_asp2_one_obs_dt_20231217_20240204.pickle')\n",
    "# utils.save_pickle(df, 'data/df_sample_label_feature_bcd_one_obs_dt_20231217_20240204.pickle')\n",
    "\n",
    "utils.save_pickle(df, 'data/df_sample_label_feature_fusion_instal_obs_dt_20231217_20240303.pickle')\n",
    "# utils.save_pickle(df, 'data/df_sample_label_feature_asp1_instal_obs_dt_20231217_20240303.pickle')\n",
    "# utils.save_pickle(df, 'data/df_sample_label_feature_asp2_instal_obs_dt_20231217_20240303.pickle')\n",
    "# utils.save_pickle(df, 'data/df_sample_label_feature_dbc_instal_obs_dt_20231217_20240303.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 方差&人工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = utils.load_pickle('data/df_sample_label_feature_fusion_one_obs_dt_20231217_20240204.pickle')\n",
    "# df = utils.load_pickle('data/df_sample_label_feature_asp1_one_obs_dt_20231217_20240204.pickle')\n",
    "# df = utils.load_pickle('data/df_sample_label_feature_asp2_one_obs_dt_20231217_20240204.pickle')\n",
    "# df = utils.load_pickle('data/df_sample_label_feature_bcd_one_obs_dt_20231217_20240204.pickle')\n",
    "\n",
    "df = utils.load_pickle('data/df_sample_label_feature_dbc_instal_obs_dt_20231217_20240303.pickle')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_des = utils.df_des(df)\n",
    "print(df_des.shape)\n",
    "df_des.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_des.to_csv('data/df_des_sample_label_feature_fusion_one_obs_dt_20231217_20240204.csv', encoding='utf-8')\n",
    "# df_des.to_csv('data/df_des_sample_label_feature_asp1_one_obs_dt_20231217_20240204.csv', encoding='utf-8')\n",
    "# df_des.to_csv('data/df_des_sample_label_feature_asp2_one_obs_dt_20231217_20240204.csv', encoding='utf-8')\n",
    "# df_des.to_csv('data/df_des_sample_label_feature_bcd_one_obs_dt_20231217_20240204.csv', encoding='utf-8')\n",
    "\n",
    "df_des.to_csv('data/df_des_sample_label_feature_dbc_instal_obs_dt_20231217_20240303.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_id_dt_condition_y = ['uid', 'obs_dt', 'dt', 'pay_type', 'default_chose_type', 'label']\n",
    "list_feats_x = [x for x in df.columns if x not in list_feats_id_dt_condition_y]\n",
    "print(len(list_feats_x))\n",
    "list_feats_x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(list_feats_x, 'data/list_feats/list_feats_x_fusion_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x, 'data/list_feats/list_feats_x_asp1_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x, 'data/list_feats/list_feats_x_asp2_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x, 'data/list_feats/list_feats_x_bcd_20231217_20240204.pickle')\n",
    "\n",
    "utils.save_pickle(list_feats_x, 'data/list_feats/dbc/list_feats_x_dbc_20231217_20240303.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_std_0 = [x for x in df_des[df_des['std']==0].index if x not in ['pay_type']]\n",
    "print(len(list_feats_x_std_0))\n",
    "list_feats_x_std_0[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(list_feats_x_std_0, 'data/list_feats/list_feats_x_std_0_fusion_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_std_0, 'data/list_feats/list_feats_x_std_0_asp1_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_std_0, 'data/list_feats/list_feats_x_std_0_asp2_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_std_0, 'data/list_feats/list_feats_x_std_0_bcd_20231217_20240204.pickle')\n",
    "\n",
    "utils.save_pickle(list_feats_x_std_0, 'data/list_feats/dbc/list_feats_x_std_0_dbc_20231217_20240303.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_std = [x for x in list_feats_x if x not in list_feats_x_std_0]\n",
    "print(len(list_feats_x_std))\n",
    "list_feats_x_std[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(list_feats_x_std, 'data/list_feats/list_feats_x_std_fusion_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_std, 'data/list_feats/list_feats_x_std_asp1_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_std, 'data/list_feats/list_feats_x_std_asp2_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_std, 'data/list_feats/list_feats_x_std_bcd_20231217_20240204.pickle')\n",
    "\n",
    "utils.save_pickle(list_feats_x_std, 'data/list_feats/dbc/list_feats_x_std_dbc_20231217_20240303.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 单因素方差分析（假设检验，f检验）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = utils.load_pickle('data/df_sample_label_feature_fusion_one_obs_dt_20231217_20240204.pickle')\n",
    "# df = utils.load_pickle('data/df_sample_label_feature_asp1_one_obs_dt_20231217_20240204.pickle')\n",
    "# df = utils.load_pickle('data/df_sample_label_feature_asp2_one_obs_dt_20231217_20240204.pickle')\n",
    "# df = utils.load_pickle('data/df_sample_label_feature_bcd_one_obs_dt_20231217_20240204.pickle')\n",
    "\n",
    "df = utils.load_pickle('data/df_sample_label_feature_dbc_instal_obs_dt_20231217_20240303.pickle')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['pay_type', 'default_chose_type', 'label', 'uid']].groupby(by=['pay_type', 'default_chose_type', 'label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_feats_x_std = utils.load_pickle('data/list_feats/list_feats_x_std_fusion_20231217_20240204.pickle')\n",
    "# list_feats_x_std = utils.load_pickle('data/list_feats/list_feats_x_std_asp1_20231217_20240204.pickle')\n",
    "# list_feats_x_std = utils.load_pickle('data/list_feats/list_feats_x_std_asp2_20231217_20240204.pickle')\n",
    "# list_feats_x_std = utils.load_pickle('data/list_feats/list_feats_x_std_bcd_20231217_20240204.pickle')\n",
    "\n",
    "list_feats_x_std = utils.load_pickle('data/list_feats/dbc/list_feats_x_std_dbc_20231217_20240303.pickle')\n",
    "\n",
    "print(len(list_feats_x_std))\n",
    "list_feats_x_std[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_var_f = []\n",
    "\n",
    "try:\n",
    "    with tqdm(list_feats_x_std) as t:\n",
    "        for feat in t:\n",
    "            var_temp = utils.hypothesis_testing(df[[feat, 'label']], [feat], 'label', method='f_classif')\n",
    "            list_var_f.append(var_temp)\n",
    "except KeyboardInterrupt:\n",
    "    t.close()\n",
    "    raise\n",
    "t.close()\n",
    "\n",
    "var_f = pd.concat(list_var_f, axis=0)\n",
    "var_f.reset_index(drop=True, inplace=True)\n",
    "var_f.sort_values(by=['score', 'P_value'], ascending=[False, False], inplace=True)\n",
    "var_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_ht_no_select = var_f[var_f['is_selected_PValue']==0]['feature'].values.tolist()\n",
    "print(len(list_feats_x_ht_no_select))\n",
    "list_feats_x_ht_no_select[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(list_feats_x_ht_no_select, 'data/list_feats/list_feats_x_ht_no_select_fusion_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_ht_no_select, 'data/list_feats/list_feats_x_ht_no_select_asp1_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_ht_no_select, 'data/list_feats/list_feats_x_ht_no_select_asp2_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_ht_no_select, 'data/list_feats/list_feats_x_ht_no_select_bcd_20231217_20240204.pickle')\n",
    "\n",
    "utils.save_pickle(list_feats_x_ht_no_select, 'data/list_feats/dbc/list_feats_x_ht_no_select_dbc_20231217_20240303.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_feats_x_ht_no_select = utils.load_pickle('data/list_feats/list_feats_x_ht_no_select_fusion_20231217_20240204.pickle')\n",
    "# list_feats_x_ht_no_select = utils.load_pickle('data/list_feats/list_feats_x_ht_no_select_asp1_20231217_20240204.pickle')\n",
    "# list_feats_x_ht_no_select = utils.load_pickle('data/list_feats/list_feats_x_ht_no_select_asp2_20231217_20240204.pickle')\n",
    "# list_feats_x_ht_no_select = utils.load_pickle('data/list_feats/list_feats_x_ht_no_select_bcd_20231217_20240204.pickle')\n",
    "\n",
    "list_feats_x_ht_no_select = utils.load_pickle('data/list_feats/dbc/list_feats_x_ht_no_select_dbc_20231217_20240303.pickle')\n",
    "\n",
    "print(len(list_feats_x_ht_no_select))\n",
    "list_feats_x_ht_no_select[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_ht = [x for x in list_feats_x_std if x not in list_feats_x_ht_no_select]\n",
    "print(len(list_feats_x_ht))\n",
    "list_feats_x_ht[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(list_feats_x_ht, 'data/list_feats/list_feats_x_ht_fusion_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_ht, 'data/list_feats/list_feats_x_ht_asp1_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_ht, 'data/list_feats/list_feats_x_ht_asp2_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_ht, 'data/list_feats/list_feats_x_ht_bcd_20231217_20240204.pickle')\n",
    "\n",
    "utils.save_pickle(list_feats_x_ht, 'data/list_feats/dbc/list_feats_x_ht_dbc_20231217_20240303.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 模型\n",
    "* 特征重要性\n",
    "* PI方法，使用lgb进行建模预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = utils.load_pickle('data/df_sample_label_feature_fusion_one_obs_dt_20231217_20240204.pickle')\n",
    "\n",
    "# print(df.shape)\n",
    "\n",
    "# df_asp1 = utils.load_pickle('data/df_sample_label_feature_asp1_one_obs_dt_20231217_20240204.pickle')\n",
    "# df_asp2 = utils.load_pickle('data/df_sample_label_feature_asp2_one_obs_dt_20231217_20240204.pickle')\n",
    "# df_bcd = utils.load_pickle('data/df_sample_label_feature_bcd_one_obs_dt_20231217_20240204.pickle')\n",
    "\n",
    "df_asp1 = utils.load_pickle('data/df_sample_label_feature_asp1_instal_obs_dt_20231217_20240303.pickle')\n",
    "df_asp2 = utils.load_pickle('data/df_sample_label_feature_asp2_instal_obs_dt_20231217_20240303.pickle')\n",
    "df_dbc = utils.load_pickle('data/df_sample_label_feature_dbc_instal_obs_dt_20231217_20240303.pickle')\n",
    "\n",
    "print(df_asp1.shape)\n",
    "print(df_asp2.shape)\n",
    "print(df_dbc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asp1_rm = pd.read_csv('data/pi/dbc/asp1/cm_credit_card.txt', sep='\\t', encoding='utf-8')\n",
    "print(df_asp1_rm.shape)\n",
    "df_asp1_rm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_id_dt_condition_y = ['uid', 'obs_dt', 'dt', 'pay_type', 'default_chose_type', 'label']\n",
    "\n",
    "# list_feats_x_ht = utils.load_pickle('data/list_feats/list_feats_x_ht_fusion_20231217_20240204.pickle')\n",
    "\n",
    "# list_feats_x_ht_1 = utils.load_pickle('data/list_feats/list_feats_x_ht_asp1_20231217_20240204.pickle')\n",
    "list_feats_x_ht_2 = utils.load_pickle('data/list_feats/list_feats_x_ht_asp2_20231217_20240204.pickle')\n",
    "# list_feats_x_ht_3 = utils.load_pickle('data/list_feats/list_feats_x_ht_bcd_20231217_20240204.pickle')\n",
    "\n",
    "list_feats_x_ht_3 = utils.load_pickle('data/list_feats/dbc/list_feats_x_ht_dbc_20231217_20240303.pickle')\n",
    "\n",
    "list_feats_x_ht_1 = [\n",
    "    x for x in utils.load_pickle('data/list_feats/list_feats_x_ht_asp1_20231217_20240204.pickle')\n",
    "    if x not in list(df_asp1_rm['feats'])\n",
    "]\n",
    "\n",
    "print(len(list_feats_x_ht_1))\n",
    "print(len(list_feats_x_ht_2))\n",
    "print(len(list_feats_x_ht_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# df = df_asp1[list_feats_id_dt_condition_y+list_feats_x_ht_1].\\\n",
    "#     merge(df_asp2[list_feats_id_dt_condition_y+list_feats_x_ht_2], on=list_feats_id_dt_condition_y, how='left').\\\n",
    "#     merge(df_bcd[list_feats_id_dt_condition_y+list_feats_x_ht_3], on=list_feats_id_dt_condition_y, how='left')\n",
    "\n",
    "df = df_asp1[list_feats_id_dt_condition_y+list_feats_x_ht_1].\\\n",
    "    merge(df_asp2[list_feats_id_dt_condition_y+list_feats_x_ht_2], on=list_feats_id_dt_condition_y, how='left').\\\n",
    "    merge(df_dbc[list_feats_id_dt_condition_y+list_feats_x_ht_3], on=list_feats_id_dt_condition_y, how='left')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in df.columns if x.endswith('_x')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(df, 'data/pi/df_ht_asp_bcd_20231217_20240204.pickle')\n",
    "\n",
    "# utils.save_pickle(df, 'data/pi/dbc/df_ht_asp_dbc_20231217_20240303.pickle')\n",
    "utils.save_pickle(df, 'data/pi/dbc/asp1/df_ht_asp_dbc_asp1_20231217_20240303.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = utils.load_pickle('data/pi/df_ht_asp_bcd_20231217_20240204.pickle')\n",
    "\n",
    "# df = utils.load_pickle('data/pi/dbc/df_ht_asp_dbc_20231217_20240303.pickle')\n",
    "\n",
    "df = utils.load_pickle('data/pi/dbc/asp1/df_ht_asp_dbc_asp1_20231217_20240303.pickle')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_feats_x_ht_1 = utils.load_pickle('data/list_feats/list_feats_x_ht_asp1_20231217_20240204.pickle')\n",
    "list_feats_x_ht_2 = utils.load_pickle('data/list_feats/list_feats_x_ht_asp2_20231217_20240204.pickle')\n",
    "# list_feats_x_ht_3 = utils.load_pickle('data/list_feats/list_feats_x_ht_bcd_20231217_20240204.pickle')\n",
    "\n",
    "list_feats_x_ht_3 = utils.load_pickle('data/list_feats/dbc/list_feats_x_ht_dbc_20231217_20240303.pickle')\n",
    "\n",
    "list_feats_x_ht_1 = [\n",
    "    x for x in utils.load_pickle('data/list_feats/list_feats_x_ht_asp1_20231217_20240204.pickle')\n",
    "    if x not in list(df_asp1_rm['feats'])\n",
    "]\n",
    "\n",
    "list_feats_x_ht = list_feats_x_ht_1 + list_feats_x_ht_2 + list_feats_x_ht_3\n",
    "\n",
    "print(len(list_feats_x_ht_1))\n",
    "print(len(list_feats_x_ht_2))\n",
    "print(len(list_feats_x_ht_3))\n",
    "\n",
    "print(len(list_feats_x_ht))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PI\n",
    "df_y = df['label']\n",
    "df_X = df[list_feats_x_ht]\n",
    "\n",
    "print(df_y.shape)\n",
    "print(df_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel df\n",
    "%xdel df_asp1\n",
    "%xdel df_asp2\n",
    "%xdel df_dbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train, df_X_test, df_y_train, df_y_test = \\\n",
    "    train_test_split(df_X, df_y, test_size=0.2, random_state=2024)\n",
    "print(df_X_train.shape)\n",
    "print(df_X_test.shape)\n",
    "print(df_y_train.shape)\n",
    "print(df_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(df_X_train, 'data/pi/df_ht_X_train_fusion_20231217_20240204.pickle')\n",
    "# utils.save_pickle(df_X_test, 'data/pi/df_ht_X_test_fusion_20231217_20240204.pickle')\n",
    "# utils.save_pickle(df_y_train, 'data/pi/df_ht_y_train_fusion_20231217_20240204.pickle')\n",
    "# utils.save_pickle(df_y_test, 'data/pi/df_ht_y_test_fusion_20231217_20240204.pickle')\n",
    "\n",
    "# utils.save_pickle(df_X_train, 'data/pi/df_ht_X_train_asp_bcd_20231217_20240204.pickle')\n",
    "# utils.save_pickle(df_X_test, 'data/pi/df_ht_X_test_asp_bcd_20231217_20240204.pickle')\n",
    "# utils.save_pickle(df_y_train, 'data/pi/df_ht_y_train_asp_bcd_20231217_20240204.pickle')\n",
    "# utils.save_pickle(df_y_test, 'data/pi/df_ht_y_test_asp_bcd_20231217_20240204.pickle')\n",
    "\n",
    "# utils.save_pickle(df_X_train, 'data/pi/dbc/df_ht_X_train_asp_dbc_20231217_20240303.pickle')\n",
    "# utils.save_pickle(df_X_test, 'data/pi/dbc/df_ht_X_test_asp_dbc_20231217_20240303.pickle')\n",
    "# utils.save_pickle(df_y_train, 'data/pi/dbc/df_ht_y_train_asp_dbc_20231217_20240303.pickle')\n",
    "# utils.save_pickle(df_y_test, 'data/pi/dbc/df_ht_y_test_asp_dbc_20231217_20240303.pickle')\n",
    "\n",
    "utils.save_pickle(df_X_train, 'data/pi/dbc/asp1/df_ht_X_train_asp_dbc_asp1_20231217_20240303.pickle')\n",
    "utils.save_pickle(df_X_test, 'data/pi/dbc/asp1/df_ht_X_test_asp_dbc_asp1_20231217_20240303.pickle')\n",
    "utils.save_pickle(df_y_train, 'data/pi/dbc/asp1/df_ht_y_train_asp_dbc_asp1_20231217_20240303.pickle')\n",
    "utils.save_pickle(df_y_test, 'data/pi/dbc/asp1/df_ht_y_test_asp_dbc_asp1_20231217_20240303.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_X_train = utils.load_pickle('data/pi/df_ht_X_train_fusion_20231217_20240204.pickle')\n",
    "# df_y_train = utils.load_pickle('data/pi/df_ht_y_train_fusion_20231217_20240204.pickle')\n",
    "\n",
    "# df_X_train = utils.load_pickle('data/pi/df_ht_X_train_asp_bcd_20231217_20240204.pickle')\n",
    "# df_y_train = utils.load_pickle('data/pi/df_ht_y_train_asp_bcd_20231217_20240204.pickle')\n",
    "\n",
    "# df_X_train = utils.load_pickle('data/pi/dbc/df_ht_X_train_asp_dbc_20231217_20240303.pickle')\n",
    "# df_y_train = utils.load_pickle('data/pi/dbc/df_ht_y_train_asp_dbc_20231217_20240303.pickle')\n",
    "\n",
    "df_X_train = utils.load_pickle('data/pi/dbc/asp1/df_ht_X_train_asp_dbc_asp1_20231217_20240303.pickle')\n",
    "df_y_train = utils.load_pickle('data/pi/dbc/asp1/df_ht_y_train_asp_dbc_asp1_20231217_20240303.pickle')\n",
    "\n",
    "print(df_X_train.shape)\n",
    "print(df_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estimator_pi=lgb.LGBMClassifier(importance_type='gain')\n",
    "estimator_pi.fit(df_X_train, df_y_train)\n",
    "\n",
    "# utils.save_pickle(estimator_pi, 'data/pi/estimator_pi_ht_fusion_20231217_20240204.pickle')\n",
    "# utils.save_pickle(estimator_pi, 'data/pi/estimator_pi_ht_asp_bcd_20231217_20240204.pickle')\n",
    "# utils.save_pickle(estimator_pi, 'data/pi/dbc/estimator_pi_ht_asp_dbc_20231217_20240303.pickle')\n",
    "utils.save_pickle(estimator_pi, 'data/pi/dbc/asp1/estimator_pi_ht_asp_dbc_asp1_20231217_20240303.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_X_test = utils.load_pickle('data/pi/df_ht_X_test_fusion_20231217_20240204.pickle')\n",
    "# df_y_test = utils.load_pickle('data/pi/df_ht_y_test_fusion_20231217_20240204.pickle')\n",
    "\n",
    "# df_X_test = utils.load_pickle('data/pi/df_ht_X_test_asp_bcd_20231217_20240204.pickle')\n",
    "# df_y_test = utils.load_pickle('data/pi/df_ht_y_test_asp_bcd_20231217_20240204.pickle')\n",
    "\n",
    "# df_X_test = utils.load_pickle('data/pi/dbc/df_ht_X_test_asp_dbc_20231217_20240303.pickle')\n",
    "# df_y_test = utils.load_pickle('data/pi/dbc/df_ht_y_test_asp_dbc_20231217_20240303.pickle')\n",
    "\n",
    "df_X_test = utils.load_pickle('data/pi/dbc/asp1/df_ht_X_test_asp_dbc_asp1_20231217_20240303.pickle')\n",
    "df_y_test = utils.load_pickle('data/pi/dbc/asp1/df_ht_y_test_asp_dbc_asp1_20231217_20240303.pickle')\n",
    "\n",
    "print(df_X_test.shape)\n",
    "print(df_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator_pi = utils.load_pickle('data/pi/estimator_pi_ht_fusion_20231217_20240204.pickle')\n",
    "# estimator_pi = utils.load_pickle('data/pi/estimator_pi_ht_asp_bcd_20231217_20240204.pickle')\n",
    "\n",
    "# estimator_pi = utils.load_pickle('data/pi/dbc/estimator_pi_ht_asp_dbc_20231217_20240303.pickle')\n",
    "\n",
    "estimator_pi = utils.load_pickle('data/pi/dbc/asp1/estimator_pi_ht_asp_dbc_asp1_20231217_20240303.pickle')\n",
    "\n",
    "estimator_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pi = permutation_importance(estimator=estimator_pi, X=df_X_test, y=df_y_test, n_jobs=8)\n",
    "\n",
    "# utils.save_pickle(pi, 'data/pi/pi_ht_fusion_20231217_20240204.pickle')\n",
    "# utils.save_pickle(pi, 'data/pi/pi_ht_asp_bcd_20231217_20240204.pickle')\n",
    "\n",
    "# utils.save_pickle(pi, 'data/pi/dbc/pi_ht_asp_dbc_20231217_20240303.pickle')\n",
    "\n",
    "utils.save_pickle(pi, 'data/pi/dbc/asp1/pi_ht_asp_dbc_asp1_20231217_20240303.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_feats_x_ht = utils.load_pickle('data/list_feats/list_feats_x_ht_fusion_20231217_20240204.pickle')\n",
    "\n",
    "# list_feats_x_ht_1 = utils.load_pickle('data/list_feats/list_feats_x_ht_asp1_20231217_20240204.pickle')\n",
    "list_feats_x_ht_2 = utils.load_pickle('data/list_feats/list_feats_x_ht_asp2_20231217_20240204.pickle')\n",
    "# list_feats_x_ht_3 = utils.load_pickle('data/list_feats/list_feats_x_ht_bcd_20231217_20240204.pickle')\n",
    "\n",
    "list_feats_x_ht_3 = utils.load_pickle('data/list_feats/dbc/list_feats_x_ht_dbc_20231217_20240303.pickle')\n",
    "\n",
    "list_feats_x_ht_1 = [\n",
    "    x for x in utils.load_pickle('data/list_feats/list_feats_x_ht_asp1_20231217_20240204.pickle')\n",
    "    if x not in list(pd.read_csv('data/pi/dbc/asp1/cm_credit_card.txt', sep='\\t', encoding='utf-8')['feats'])\n",
    "]\n",
    "\n",
    "list_feats_x_ht = list_feats_x_ht_1 + list_feats_x_ht_2 + list_feats_x_ht_3\n",
    "\n",
    "print(len(list_feats_x_ht_1))\n",
    "print(len(list_feats_x_ht_2))\n",
    "print(len(list_feats_x_ht_3))\n",
    "\n",
    "print(len(list_feats_x_ht))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pi = pd.DataFrame({'feature': list_feats_x_ht, 'permutation_importance_mean': pi.importances_mean})\n",
    "print(df_pi.shape)\n",
    "df_pi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pi.sort_values(by=['permutation_importance_mean'], ascending=[False], inplace=True)\n",
    "df_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pi[['permutation_importance_mean']].quantile([x/10 for x in range(11)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_pi_no_select = df_pi[(df_pi['permutation_importance_mean']<=0.0)]['feature'].values.tolist()\n",
    "print(len(list_feats_x_pi_no_select))\n",
    "list_feats_x_pi_no_select[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(list_feats_x_pi_no_select, 'data/list_feats/list_feats_x_pi_no_select_fusion_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_pi_no_select, 'data/list_feats/list_feats_x_pi_no_select_asp_bcd_20231217_20240204.pickle')\n",
    "\n",
    "# utils.save_pickle(list_feats_x_pi_no_select, 'data/list_feats/dbc/list_feats_x_pi_no_select_asp_dbc_20231217_20240303.pickle')\n",
    "\n",
    "utils.save_pickle(list_feats_x_pi_no_select, 'data/list_feats/dbc/asp1/list_feats_x_pi_no_select_asp_dbc_asp1_20231217_20240303.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_pi = [x for x in list_feats_x_ht if x not in list_feats_x_pi_no_select]\n",
    "print(len(list_feats_x_pi))\n",
    "list_feats_x_pi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in list_feats_x_pi if x in ['is_bind_credit_card_xxpay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_pickle(list_feats_x_pi, 'data/list_feats/list_feats_x_pi_fusion_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_pi, 'data/list_feats/list_feats_x_pi_asp_bcd_20231217_20240204.pickle')\n",
    "\n",
    "# utils.save_pickle(list_feats_x_pi, 'data/list_feats/dbc/list_feats_x_pi_asp_dbc_20231217_20240303.pickle')\n",
    "\n",
    "utils.save_pickle(list_feats_x_pi, 'data/list_feats/dbc/asp1/list_feats_x_pi_asp_dbc_asp1_20231217_20240303.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全量数据拉取sql处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_sql_coalesce(sql_file_path, special_words, sql_file_path_new):\n",
    "    with open(sql_file_path, 'r') as fi:\n",
    "        list_sql = fi.readlines()\n",
    "        \n",
    "        str_pattern = r'|'.join(['( '+x+', )' for x in special_words])\n",
    "        str_pattern_end = r'|'.join(['( '+x+' )' for x in special_words])\n",
    "        str_pattern_from = r'^from '\n",
    "        pattern = re.compile(str_pattern)\n",
    "        pattern_end = re.compile(str_pattern_end)\n",
    "        pattern_from = re.compile(str_pattern_from)\n",
    "        \n",
    "        list_sql_valid = []\n",
    "        list_sql_valid_front = []\n",
    "        list_sql_valid_back = []\n",
    "        \n",
    "        index_front = 0\n",
    "        for i in range(len(list_sql)):\n",
    "            if re.search(pattern_from, list_sql[i]):\n",
    "                index_front = i\n",
    "                break\n",
    "        list_sql_valid_back = list_sql[index_front+1:]\n",
    "        \n",
    "        try:\n",
    "            with tqdm(list(range(len(list_sql[:index_front])))) as t:\n",
    "                for i in t:\n",
    "                    if i == index_front - 1:\n",
    "                        if not re.search(str_pattern_end, list_sql[i]):\n",
    "                            list_sql_valid_front.append(list_sql[i])\n",
    "                    else:\n",
    "                        if not re.search(pattern, list_sql[i]):\n",
    "                            list_sql_valid_front.append(list_sql[i])\n",
    "        except KeyboardInterrupt:\n",
    "            t.close()\n",
    "            raise\n",
    "        t.close()\n",
    "        list_sql_valid = list_sql_valid_front + [list_sql[index_front]] + list_sql_valid_back\n",
    "        \n",
    "        with open(sql_file_path_new, 'w') as fo:\n",
    "            fo.writelines(list_sql_valid)\n",
    "            \n",
    "\n",
    "def del_sql_select_origin(sql_file_path, special_words, sql_file_path_new):\n",
    "    with open(sql_file_path, 'r') as fi:\n",
    "        list_sql = fi.readlines()\n",
    "        \n",
    "        str_pattern_1 = r'|'.join(['(\\t'+x+', )' for x in special_words])\n",
    "        str_pattern_2 = r'|'.join(['(    '+x+', )' for x in special_words])\n",
    "        str_pattern_3 = r'|'.join(['(\\t'+x+' )' for x in special_words])\n",
    "        str_pattern_4 = r'|'.join(['(    '+x+' )' for x in special_words])\n",
    "        str_pattern_from = r'^from '\n",
    "        pattern_1 = re.compile(str_pattern_1)\n",
    "        pattern_2 = re.compile(str_pattern_2)\n",
    "        pattern_3 = re.compile(str_pattern_3)\n",
    "        pattern_4 = re.compile(str_pattern_4)\n",
    "        pattern_from = re.compile(str_pattern_from)\n",
    "        \n",
    "        list_sql_valid = []\n",
    "        list_sql_valid_front = []\n",
    "        list_sql_valid_back = []\n",
    "        \n",
    "        index_front = 0\n",
    "        for i in range(len(list_sql)):\n",
    "            if re.search(pattern_from, list_sql[i]):\n",
    "                index_front = i\n",
    "                break\n",
    "        list_sql_valid_front = list_sql[:index_front]\n",
    "        \n",
    "        try:\n",
    "            with tqdm(list(range(len(list_sql[index_front+1:])))) as t:\n",
    "                for i in t:\n",
    "                    if not re.search(pattern_1, list_sql[index_front+1+i]) \\\n",
    "                        and not re.search(pattern_2, list_sql[index_front+1+i]) \\\n",
    "                        and not re.search(pattern_3, list_sql[index_front+1+i]) \\\n",
    "                        and not re.search(pattern_4, list_sql[index_front+1+i]):\n",
    "                        list_sql_valid_back.append(list_sql[index_front+1+i])\n",
    "        except KeyboardInterrupt:\n",
    "            t.close()\n",
    "            raise\n",
    "        t.close()\n",
    "        list_sql_valid = list_sql_valid_front + [list_sql[index_front]] + list_sql_valid_back\n",
    "        \n",
    "        with open(sql_file_path_new, 'w') as fo:\n",
    "            fo.writelines(list_sql_valid)\n",
    "            \n",
    "            \n",
    "def correct_end(sql_file_path, sql_file_path_new):\n",
    "    with open(sql_file_path, 'r') as fi:\n",
    "        list_sql = fi.readlines()\n",
    "        \n",
    "        str_pattern = r'from '\n",
    "        pattern = re.compile(str_pattern)\n",
    "        \n",
    "        try:\n",
    "            with tqdm(list(range(len(list_sql)))) as t:\n",
    "                for i in t:\n",
    "                    if re.search(pattern, list_sql[i]):\n",
    "                        if list_sql[i-1][-3:-1] == ', ':\n",
    "                            list_sql[i-1] = list_sql[i-1][:-3] + list_sql[i-1][-2:]\n",
    "        except KeyboardInterrupt:\n",
    "            t.close()\n",
    "            raise\n",
    "        t.close()\n",
    "        \n",
    "        with open(sql_file_path_new, 'w') as fo:\n",
    "            fo.writelines(list_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_feats_x = utils.load_pickle('data/list_feats/list_feats_x_pi_fusion_20231217_20240204.pickle')\n",
    "# list_feats_x = utils.load_pickle('data/list_feats/list_feats_x_pi_asp_bcd_20231217_20240204.pickle')\n",
    "\n",
    "# list_feats_x = utils.load_pickle('data/list_feats/dbc/list_feats_x_pi_asp_dbc_20231217_20240303.pickle')\n",
    "\n",
    "list_feats_x = utils.load_pickle('data/list_feats/dbc/asp1/list_feats_x_pi_asp_dbc_asp1_20231217_20240303.pickle')\n",
    "\n",
    "print(len(list_feats_x))\n",
    "list_feats_x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_feats_x_all = utils.load_pickle('data/list_feats/list_feats_x_fusion_20231217_20240204.pickle')\n",
    "# list_feats_x_all = utils.load_pickle('data/list_feats/list_feats_x_asp1_20231217_20240204.pickle')\n",
    "# list_feats_x_all = utils.load_pickle('data/list_feats/list_feats_x_asp2_20231217_20240204.pickle')\n",
    "# list_feats_x_all = utils.load_pickle('data/list_feats/list_feats_x_bcd_20231217_20240204.pickle')\n",
    "\n",
    "list_feats_x_all = utils.load_pickle('data/list_feats/dbc/list_feats_x_dbc_20231217_20240303.pickle')\n",
    "\n",
    "print(len(list_feats_x_all))\n",
    "list_feats_x_all[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_pi = [x for x in list_feats_x_all if x in list_feats_x]\n",
    "print(len(list_feats_x_pi))\n",
    "\n",
    "# utils.save_pickle(list_feats_x_pi, 'data/list_feats/list_feats_x_pi_asp1_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_pi, 'data/list_feats/list_feats_x_pi_asp2_20231217_20240204.pickle')\n",
    "# utils.save_pickle(list_feats_x_pi, 'data/list_feats/list_feats_x_pi_bcd_20231217_20240204.pickle')\n",
    "\n",
    "# utils.save_pickle(list_feats_x_pi, 'data/list_feats/dbc/list_feats_x_pi_asp1_20231217_20240303.pickle')\n",
    "# utils.save_pickle(list_feats_x_pi, 'data/list_feats/dbc/list_feats_x_pi_asp2_20231217_20240303.pickle')\n",
    "# utils.save_pickle(list_feats_x_pi, 'data/list_feats/dbc/list_feats_x_pi_dbc_20231217_20240303.pickle')\n",
    "\n",
    "# utils.save_pickle(list_feats_x_pi, 'data/list_feats/dbc/asp1/list_feats_x_pi_asp1_20231217_20240303.pickle')\n",
    "# utils.save_pickle(list_feats_x_pi, 'data/list_feats/dbc/asp1/list_feats_x_pi_asp2_20231217_20240303.pickle')\n",
    "utils.save_pickle(list_feats_x_pi, 'data/list_feats/dbc/asp1/list_feats_x_pi_dbc_20231217_20240303.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feats_x_del = [x for x in list_feats_x_all if x not in list_feats_x_pi]\n",
    "list_feats_x_del = ['asd'] if len(list_feats_x_del) == 0 else list_feats_x_del\n",
    "print(len(list_feats_x_del))\n",
    "list_feats_x_del[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_words = list_feats_x_del\n",
    "\n",
    "# sql_file_path = 'sample_label_feature_fusion.sql'\n",
    "# sql_file_path_new = 'sample_label_feature_fusion_.sql'\n",
    "\n",
    "# sql_file_path = 'sample_label_feature_asp1.sql'\n",
    "# sql_file_path_new = 'sample_label_feature_asp1_.sql'\n",
    "# sql_file_path_new = 'sample_label_feature_asp1_1.sql'\n",
    "# sql_file_path_new = 'sample_label_feature_asp1_2.sql'\n",
    "\n",
    "# sql_file_path = 'sample_label_feature_asp2.sql'\n",
    "# sql_file_path_new = 'sample_label_feature_asp2_.sql'\n",
    "# sql_file_path_new = 'sample_label_feature_asp2_1.sql'\n",
    "# sql_file_path_new = 'sample_label_feature_asp2_2.sql'\n",
    "\n",
    "# sql_file_path = 'sample_label_feature_bank_card_debit.sql'\n",
    "# sql_file_path_new = 'sample_label_feature_bank_card_debit_.sql'\n",
    "\n",
    "sql_file_path = 'sample_label_feature_xxpay_bank_card.sql'\n",
    "# sql_file_path_new = 'sample_label_feature_xxpay_bank_card_.sql'\n",
    "sql_file_path_new = 'sample_label_feature_xxpay_bank_card_1.sql'\n",
    "\n",
    "del_sql_coalesce(sql_file_path, special_words, sql_file_path_new)\n",
    "del_sql_select_origin(sql_file_path_new, special_words, sql_file_path_new)\n",
    "correct_end(sql_file_path_new, sql_file_path_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_sql_coalesce_table(sql_file_path, special_words, sql_file_path_new):\n",
    "    with open(sql_file_path, 'r') as fi:\n",
    "        list_sql = fi.readlines()\n",
    "        \n",
    "        str_pattern_end = r'|'.join(['( `'+x+'` )' for x in special_words])\n",
    "        str_pattern_from = r'^from '\n",
    "        pattern = re.compile(str_pattern)\n",
    "        pattern_end = re.compile(str_pattern_end)\n",
    "        pattern_from = re.compile(str_pattern_from)\n",
    "        \n",
    "        list_sql_valid = []\n",
    "        list_sql_valid_front = []\n",
    "        list_sql_valid_back = []\n",
    "        \n",
    "        index_front = 0\n",
    "        for i in range(len(list_sql)):\n",
    "            if re.search(pattern_from, list_sql[i]):\n",
    "                index_front = i\n",
    "                break\n",
    "        list_sql_valid_back = list_sql[index_front+1:]\n",
    "        \n",
    "        try:\n",
    "            with tqdm(list(range(len(list_sql[:index_front])))) as t:\n",
    "                for i in t:\n",
    "                    if not re.search(str_pattern_end, list_sql[i]):\n",
    "                        list_sql_valid_front.append(list_sql[i])\n",
    "        except KeyboardInterrupt:\n",
    "            t.close()\n",
    "            raise\n",
    "        t.close()\n",
    "        list_sql_valid = list_sql_valid_front + [list_sql[index_front]] + list_sql_valid_back\n",
    "        \n",
    "        with open(sql_file_path_new, 'w') as fo:\n",
    "            fo.writelines(list_sql_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (jarretthan)",
   "language": "python",
   "name": "jarretthan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
